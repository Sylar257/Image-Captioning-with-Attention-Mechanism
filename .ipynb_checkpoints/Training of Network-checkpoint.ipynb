{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Encoder-Decoder network with attention mechanism\n",
    "## Data preparation\n",
    "* Create our input files from the Microsoft COCO dataset.\n",
    "* By default COCO come with 5 captions per image. \n",
    "* We are going to ignore the captions that are longer than 50 words. As we have seen in the Image-Captioning-Project, they are really rare.\n",
    "* The output files are stored under the \"output_folder\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TRAIN images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 113287/113287 [48:08<00:00, 39.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading VAL images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [03:26<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TEST images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:57<00:00, 28.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import create_input_files\n",
    "\n",
    "# This will create big files in your computer.\n",
    "create_input_files(dataset='coco',\n",
    "                   karpathy_json_path='dataset_coco.json',\n",
    "                   image_folder='../cocoapi-master/images',\n",
    "                   captions_per_image=5,\n",
    "                   min_word_freq=5,\n",
    "                   output_folder='../cocoapi-master/images',\n",
    "                   max_len=50\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../cocoapi-master/images'         # the output_folder of created input_files\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq' # the same way we created them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import necessary packages\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 512         # dimension of word embeddings\n",
    "attention_dim = 512   # dimension of attention linear layers\n",
    "decoder_dim = 512     # dimention of LSTM decoder\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # GPU set for PyTorch\n",
    "cudnn.benchmark = True # set to \"True\" only if inputs to model are fixed size; otherwise lot of computational overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 7                    # Max number of training epochs if early-stopping is not triggered\n",
    "epochs_since_improvement = 0  # This tracks the number of epochs since the last improvement was made\n",
    "batch_size = 32\n",
    "encoder_lr = 1e-4             # This is used with encoder if 'fine-tunning' is enabled\n",
    "decoder_lr = 4e-4             # LSTM learning rate\n",
    "grad_clip = 5.0               # Clip the gradients at this value\n",
    "alpha_c = 1.0                 # Regularization for attention; implementation from the original paper\n",
    "best_bleu4 = 0.0              # This tracks the BLUE-4 score\n",
    "print_freq = 200    \n",
    "fine_tune_encoder = True     # Do we train the encoder?\n",
    "checkpoint = 'BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar'             # Path to checkpoint, \"None\" if none\n",
    "torch.cuda.get_device_name(0) # check if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A walk through of what will happen later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the next gourpd of training data from loader\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "imgs, caps, caplens = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into GPU device\n",
    "imgs = imgs.to(device)\n",
    "caps = caps.to(device)\n",
    "caplens = caplens.to(device)\n",
    "\n",
    "# Pass through CNN encoder\n",
    "imgs = encoder(imgs)   # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "\n",
    "# Pass through RNN decoder\n",
    "scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 9490])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_sorted.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decode_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequence so that we can calculate the loss later\n",
    "scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "targets = caps_sorted[:, 1:]\n",
    "targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(scores.data, targets.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have the loss to perform back propogate\n",
    "All the rest can be handled by Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2221, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    tain_loader: DataLoader for the training data\n",
    "    encoder: encoder model\n",
    "    decoder: decoder model\n",
    "    criterion: loss function\n",
    "    encoder_optimizer: optimizer for the encoder(if fine-tuning is on)\n",
    "    decoder_optimizer: optimizer for the LSTM\n",
    "    epoch: epoch number\n",
    "    \"\"\"\n",
    "    \n",
    "    decoder.train()    # Training mode\n",
    "    encoder.train()\n",
    "    \n",
    "    # AverageMeter() is imported from utils.py to track the most recent, average, sum, and count of a metric.\n",
    "    batch_time = AverageMeter()   # forward prop + back prop time\n",
    "    data_time = AverageMeter()    # data loading time\n",
    "    losses = AverageMeter()       # loss (per word decoded)\n",
    "    top5accs = AverageMeter()     # top5 accuracy\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Batches\n",
    "    for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "        \n",
    "        # Move data to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "        \n",
    "        # Forward prop.\n",
    "        imgs = encoder(imgs)   # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens) \n",
    "        # scores-(batch_size_t, vocab_size) \n",
    "        # caps_sorted-(batch_size, max_caption_length)\n",
    "        # decode_lengths-[caption_lengths -1]\n",
    "        # alphas, pixel-wise attention, (batch_size, max(decode_lengths), num_pixels)\n",
    "        # sort_ind: this index sort the lengths of captions in descending order\n",
    "        \n",
    "        # Since we decoded staring with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        \n",
    "        # Remove timesteps that we didn't encode at, or are pads\n",
    "        # pack_padded_sentence to fo this trick\n",
    "        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(scores.data, targets.data)\n",
    "        \n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "        \n",
    "        # BackProp.\n",
    "        decoder_optimizer.zero_grad()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "        \n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "            \n",
    "        # Keep track of metrics\n",
    "        top5 = accuracy(scores.data, targets.data, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses,\n",
    "                                                                          top5=top5accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    \"\"\"\n",
    "    val_loader: DataLoader for validation data\n",
    "    encoder: trained encoder model\n",
    "    decoder: trained decoder model\n",
    "    criterion: loss function\n",
    "    \n",
    "    return: BLEU-4 score\n",
    "    \"\"\"\n",
    "    decoder.eval() # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "    start = time.time()\n",
    "    \n",
    "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
    "    hypotheses = list()  # references (predictions)\n",
    "    \n",
    "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
    "    with torch.no_grad():\n",
    "        # Batches\n",
    "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
    "            # move to GPU\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "            \n",
    "            # Forward prop.\n",
    "            if encoder is not None:\n",
    "                imgs = encoder(imgs)\n",
    "            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "            \n",
    "            # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "            # \"caps_sorted\" is the \"caps\" tensor sorted with descending caption_length order. (batch_size, max_caption_length)\n",
    "            targets = caps_sorted[:, 1:]   # this matchs the position of target to predictions\n",
    "            \n",
    "            # Remove timesteps that we didn't decode at, or are pads\n",
    "            # pack_padded_sequence can do this trick\n",
    "            scores_copy = scores.clone()\n",
    "            scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "            targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(scores.data, targets.data)\n",
    "            \n",
    "            # Add doubly stochastic attention regularization\n",
    "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "            \n",
    "            # Keep track of metrics\n",
    "            losses.update(loss.item(), sum(decode_lengths))\n",
    "            top5 = accuracy(scores.data, targets.data, 5)\n",
    "            top5accs.update(top5, sum(decode_lengths))\n",
    "            batch_time.update(time.time() - start)\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\t'\n",
    "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
    "                                                                                loss=losses, top5=top5accs))\n",
    "                \n",
    "            # Store references (true captions), and hypothesis (prediction) for each image\n",
    "            # If for n images, we have n hypotheses, and references a, b, c... for each image, we need\n",
    "            # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b],...], hypotheses = [hyp1, hyp2, ...]\n",
    "            \n",
    "            # References\n",
    "            allcaps = allcaps[sort_ind] # the captions are sorted in the decoder\n",
    "            for j in range(allcaps.shape[0]):\n",
    "                img_caps = allcaps[j].tolist()\n",
    "                img_captions = list(\n",
    "                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}], \n",
    "                        img_caps))   # remove <start> and pads\n",
    "                references.append(img_captions)\n",
    "            \n",
    "            # Hypotheses\n",
    "            _, preds = torch.max(scores_copy, dim=2)\n",
    "            preds = preds.tolist()\n",
    "            temp_preds = list()\n",
    "            for j,p in enumerate(preds):\n",
    "                temp_preds.append(preds[j][:decode_lengths[j]])   # remove pads\n",
    "            preds = temp_preds\n",
    "            hypotheses.extend(preds)\n",
    "            \n",
    "            assert len(references) == len(hypotheses)\n",
    "            \n",
    "        # Calculate BLEU-4 scores\n",
    "        bleu4 = corpus_bleu(references, hypotheses)\n",
    "        \n",
    "        print(\n",
    "            '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n",
    "                loss=losses,\n",
    "                top5=top5accs,\n",
    "                bleu=bleu4))\n",
    "\n",
    "    return bleu4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load our word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of the vocabulary is :9490\n"
     ]
    }
   ],
   "source": [
    "global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "print(f\"The total size of the vocabulary is :{len(word_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize / load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint is None:\n",
    "    decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                                   embed_dim=emb_dim,\n",
    "                                   decoder_dim=decoder_dim,\n",
    "                                   vocab_size=len(word_map),\n",
    "                                   dropout=dropout\n",
    "                                  )\n",
    "    decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                             lr=decoder_lr)\n",
    "    encoder = Encoder()\n",
    "    encoder.fine_tune(fine_tune_encoder)\n",
    "    encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                             lr=encoder_lr) if fine_tune_encoder else None\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "    best_bleu4 = checkpoint['bleu-4']\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "    if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "        encoder.fine_tune(fine_tune_encoder)\n",
    "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                                 lr=encoder_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/17702]\tBatch Time 6.032 (6.032)\tData Load Time 0.731 (0.731)\tLoss 3.0988 (3.0988)\tTop-5 Accuracy 78.723 (78.723)\n",
      "Epoch: [4][200/17702]\tBatch Time 1.219 (1.284)\tData Load Time 0.562 (0.540)\tLoss 3.0774 (3.0194)\tTop-5 Accuracy 77.233 (78.635)\n",
      "Epoch: [4][400/17702]\tBatch Time 1.266 (1.270)\tData Load Time 0.500 (0.537)\tLoss 3.0700 (3.0262)\tTop-5 Accuracy 77.929 (78.618)\n",
      "Epoch: [4][600/17702]\tBatch Time 1.172 (1.254)\tData Load Time 0.469 (0.528)\tLoss 3.0951 (3.0341)\tTop-5 Accuracy 78.462 (78.564)\n",
      "Epoch: [4][800/17702]\tBatch Time 1.234 (1.243)\tData Load Time 0.562 (0.518)\tLoss 2.6472 (3.0410)\tTop-5 Accuracy 82.778 (78.485)\n",
      "Epoch: [4][1000/17702]\tBatch Time 1.125 (1.231)\tData Load Time 0.484 (0.509)\tLoss 3.3399 (3.0441)\tTop-5 Accuracy 74.419 (78.434)\n",
      "Epoch: [4][1200/17702]\tBatch Time 1.094 (1.220)\tData Load Time 0.422 (0.499)\tLoss 3.0285 (3.0448)\tTop-5 Accuracy 81.429 (78.457)\n",
      "Epoch: [4][1400/17702]\tBatch Time 1.203 (1.210)\tData Load Time 0.500 (0.490)\tLoss 2.9988 (3.0431)\tTop-5 Accuracy 79.063 (78.500)\n",
      "Epoch: [4][1600/17702]\tBatch Time 1.078 (1.201)\tData Load Time 0.375 (0.481)\tLoss 3.2241 (3.0449)\tTop-5 Accuracy 78.804 (78.489)\n",
      "Epoch: [4][1800/17702]\tBatch Time 1.078 (1.192)\tData Load Time 0.422 (0.473)\tLoss 3.3677 (3.0472)\tTop-5 Accuracy 72.176 (78.443)\n",
      "Epoch: [4][2000/17702]\tBatch Time 1.125 (1.182)\tData Load Time 0.406 (0.463)\tLoss 2.9958 (3.0470)\tTop-5 Accuracy 79.121 (78.468)\n",
      "Epoch: [4][2200/17702]\tBatch Time 1.062 (1.173)\tData Load Time 0.391 (0.455)\tLoss 2.8099 (3.0476)\tTop-5 Accuracy 80.758 (78.468)\n",
      "Epoch: [4][2400/17702]\tBatch Time 1.172 (1.166)\tData Load Time 0.437 (0.448)\tLoss 3.1551 (3.0483)\tTop-5 Accuracy 77.183 (78.459)\n",
      "Epoch: [4][2600/17702]\tBatch Time 1.109 (1.163)\tData Load Time 0.484 (0.445)\tLoss 3.1527 (3.0487)\tTop-5 Accuracy 73.876 (78.456)\n",
      "Epoch: [4][2800/17702]\tBatch Time 1.031 (1.159)\tData Load Time 0.375 (0.441)\tLoss 3.2926 (3.0486)\tTop-5 Accuracy 76.190 (78.457)\n",
      "Epoch: [4][3000/17702]\tBatch Time 1.125 (1.155)\tData Load Time 0.422 (0.436)\tLoss 3.0445 (3.0498)\tTop-5 Accuracy 80.992 (78.434)\n",
      "Epoch: [4][3200/17702]\tBatch Time 1.266 (1.150)\tData Load Time 0.437 (0.432)\tLoss 3.2442 (3.0506)\tTop-5 Accuracy 75.853 (78.424)\n",
      "Epoch: [4][3400/17702]\tBatch Time 1.047 (1.146)\tData Load Time 0.359 (0.428)\tLoss 2.8692 (3.0510)\tTop-5 Accuracy 79.834 (78.421)\n",
      "Epoch: [4][3600/17702]\tBatch Time 1.047 (1.142)\tData Load Time 0.391 (0.424)\tLoss 3.0097 (3.0512)\tTop-5 Accuracy 79.202 (78.422)\n",
      "Epoch: [4][3800/17702]\tBatch Time 1.109 (1.139)\tData Load Time 0.406 (0.421)\tLoss 3.1773 (3.0525)\tTop-5 Accuracy 76.676 (78.407)\n",
      "Epoch: [4][4000/17702]\tBatch Time 1.078 (1.136)\tData Load Time 0.328 (0.418)\tLoss 3.1557 (3.0532)\tTop-5 Accuracy 77.260 (78.402)\n",
      "Epoch: [4][4200/17702]\tBatch Time 0.937 (1.134)\tData Load Time 0.312 (0.416)\tLoss 3.1644 (3.0532)\tTop-5 Accuracy 77.485 (78.396)\n",
      "Epoch: [4][4400/17702]\tBatch Time 1.172 (1.131)\tData Load Time 0.406 (0.414)\tLoss 3.1146 (3.0535)\tTop-5 Accuracy 79.121 (78.396)\n",
      "Epoch: [4][4600/17702]\tBatch Time 1.016 (1.129)\tData Load Time 0.328 (0.412)\tLoss 3.2432 (3.0538)\tTop-5 Accuracy 75.698 (78.397)\n",
      "Epoch: [4][4800/17702]\tBatch Time 1.031 (1.127)\tData Load Time 0.359 (0.410)\tLoss 3.1443 (3.0540)\tTop-5 Accuracy 75.281 (78.397)\n",
      "Epoch: [4][5000/17702]\tBatch Time 1.047 (1.126)\tData Load Time 0.391 (0.409)\tLoss 3.4172 (3.0543)\tTop-5 Accuracy 75.287 (78.392)\n",
      "Epoch: [4][5200/17702]\tBatch Time 1.062 (1.124)\tData Load Time 0.391 (0.407)\tLoss 3.1753 (3.0558)\tTop-5 Accuracy 75.645 (78.372)\n",
      "Epoch: [4][5400/17702]\tBatch Time 1.156 (1.123)\tData Load Time 0.469 (0.405)\tLoss 2.8481 (3.0564)\tTop-5 Accuracy 82.768 (78.368)\n",
      "Epoch: [4][5600/17702]\tBatch Time 1.016 (1.120)\tData Load Time 0.328 (0.403)\tLoss 3.4288 (3.0572)\tTop-5 Accuracy 73.656 (78.360)\n",
      "Epoch: [4][5800/17702]\tBatch Time 1.109 (1.119)\tData Load Time 0.375 (0.402)\tLoss 3.1379 (3.0582)\tTop-5 Accuracy 77.112 (78.354)\n",
      "Epoch: [4][6000/17702]\tBatch Time 1.281 (1.117)\tData Load Time 0.469 (0.400)\tLoss 3.1693 (3.0585)\tTop-5 Accuracy 75.584 (78.351)\n",
      "Epoch: [4][6200/17702]\tBatch Time 1.125 (1.116)\tData Load Time 0.422 (0.399)\tLoss 3.2145 (3.0589)\tTop-5 Accuracy 76.501 (78.348)\n",
      "Epoch: [4][6400/17702]\tBatch Time 1.141 (1.114)\tData Load Time 0.500 (0.398)\tLoss 3.0570 (3.0594)\tTop-5 Accuracy 76.966 (78.343)\n",
      "Epoch: [4][6600/17702]\tBatch Time 1.500 (1.113)\tData Load Time 0.375 (0.397)\tLoss 3.3998 (3.0602)\tTop-5 Accuracy 72.902 (78.331)\n",
      "Epoch: [4][6800/17702]\tBatch Time 1.203 (1.113)\tData Load Time 0.391 (0.396)\tLoss 3.1824 (3.0614)\tTop-5 Accuracy 75.000 (78.317)\n",
      "Epoch: [4][7000/17702]\tBatch Time 1.141 (1.112)\tData Load Time 0.437 (0.395)\tLoss 2.9220 (3.0615)\tTop-5 Accuracy 79.887 (78.313)\n",
      "Epoch: [4][7200/17702]\tBatch Time 1.109 (1.112)\tData Load Time 0.422 (0.394)\tLoss 2.9397 (3.0613)\tTop-5 Accuracy 81.073 (78.319)\n",
      "Epoch: [4][7400/17702]\tBatch Time 1.172 (1.111)\tData Load Time 0.531 (0.394)\tLoss 3.2158 (3.0614)\tTop-5 Accuracy 76.344 (78.320)\n",
      "Epoch: [4][7600/17702]\tBatch Time 0.953 (1.110)\tData Load Time 0.313 (0.393)\tLoss 3.0135 (3.0612)\tTop-5 Accuracy 76.111 (78.325)\n",
      "Epoch: [4][7800/17702]\tBatch Time 1.078 (1.109)\tData Load Time 0.406 (0.392)\tLoss 2.9301 (3.0617)\tTop-5 Accuracy 81.044 (78.319)\n",
      "Epoch: [4][8000/17702]\tBatch Time 1.187 (1.109)\tData Load Time 0.469 (0.391)\tLoss 3.1020 (3.0615)\tTop-5 Accuracy 75.358 (78.326)\n",
      "Epoch: [4][8200/17702]\tBatch Time 1.016 (1.108)\tData Load Time 0.328 (0.391)\tLoss 2.9779 (3.0615)\tTop-5 Accuracy 80.926 (78.327)\n",
      "Epoch: [4][8400/17702]\tBatch Time 1.062 (1.107)\tData Load Time 0.328 (0.390)\tLoss 3.0912 (3.0622)\tTop-5 Accuracy 74.536 (78.318)\n",
      "Epoch: [4][8600/17702]\tBatch Time 1.109 (1.106)\tData Load Time 0.422 (0.389)\tLoss 3.0984 (3.0625)\tTop-5 Accuracy 77.929 (78.315)\n",
      "Epoch: [4][8800/17702]\tBatch Time 1.062 (1.106)\tData Load Time 0.406 (0.389)\tLoss 2.9909 (3.0631)\tTop-5 Accuracy 80.000 (78.308)\n",
      "Epoch: [4][9000/17702]\tBatch Time 0.969 (1.105)\tData Load Time 0.312 (0.388)\tLoss 2.9951 (3.0640)\tTop-5 Accuracy 80.000 (78.299)\n",
      "Epoch: [4][9200/17702]\tBatch Time 1.031 (1.105)\tData Load Time 0.375 (0.388)\tLoss 2.9410 (3.0645)\tTop-5 Accuracy 78.310 (78.297)\n",
      "Epoch: [4][9400/17702]\tBatch Time 1.078 (1.104)\tData Load Time 0.344 (0.387)\tLoss 3.0705 (3.0645)\tTop-5 Accuracy 77.716 (78.300)\n",
      "Epoch: [4][9600/17702]\tBatch Time 1.078 (1.104)\tData Load Time 0.406 (0.386)\tLoss 3.0421 (3.0652)\tTop-5 Accuracy 75.439 (78.291)\n",
      "Epoch: [4][9800/17702]\tBatch Time 0.937 (1.103)\tData Load Time 0.281 (0.386)\tLoss 2.9987 (3.0656)\tTop-5 Accuracy 80.163 (78.285)\n",
      "Epoch: [4][10000/17702]\tBatch Time 1.281 (1.102)\tData Load Time 0.328 (0.385)\tLoss 3.2298 (3.0656)\tTop-5 Accuracy 75.515 (78.285)\n",
      "Epoch: [4][10200/17702]\tBatch Time 1.158 (1.101)\tData Load Time 0.393 (0.385)\tLoss 2.8989 (3.0659)\tTop-5 Accuracy 80.208 (78.283)\n",
      "Epoch: [4][10400/17702]\tBatch Time 1.141 (1.101)\tData Load Time 0.375 (0.384)\tLoss 3.1369 (3.0660)\tTop-5 Accuracy 78.342 (78.285)\n",
      "Epoch: [4][10600/17702]\tBatch Time 1.078 (1.100)\tData Load Time 0.328 (0.384)\tLoss 3.0548 (3.0662)\tTop-5 Accuracy 79.733 (78.283)\n",
      "Epoch: [4][10800/17702]\tBatch Time 1.078 (1.100)\tData Load Time 0.391 (0.383)\tLoss 2.9983 (3.0668)\tTop-5 Accuracy 80.749 (78.278)\n",
      "Epoch: [4][11000/17702]\tBatch Time 1.031 (1.100)\tData Load Time 0.344 (0.383)\tLoss 3.1759 (3.0668)\tTop-5 Accuracy 76.471 (78.276)\n",
      "Epoch: [4][11200/17702]\tBatch Time 1.031 (1.099)\tData Load Time 0.328 (0.382)\tLoss 2.7745 (3.0673)\tTop-5 Accuracy 79.949 (78.268)\n",
      "Epoch: [4][11400/17702]\tBatch Time 1.031 (1.099)\tData Load Time 0.344 (0.382)\tLoss 2.9411 (3.0673)\tTop-5 Accuracy 79.830 (78.269)\n",
      "Epoch: [4][11600/17702]\tBatch Time 1.156 (1.098)\tData Load Time 0.375 (0.382)\tLoss 3.1841 (3.0679)\tTop-5 Accuracy 76.648 (78.259)\n",
      "Epoch: [4][11800/17702]\tBatch Time 1.109 (1.098)\tData Load Time 0.406 (0.381)\tLoss 2.7834 (3.0683)\tTop-5 Accuracy 81.283 (78.258)\n",
      "Epoch: [4][12000/17702]\tBatch Time 0.969 (1.098)\tData Load Time 0.297 (0.381)\tLoss 3.0928 (3.0685)\tTop-5 Accuracy 79.620 (78.258)\n",
      "Epoch: [4][12200/17702]\tBatch Time 1.203 (1.097)\tData Load Time 0.500 (0.380)\tLoss 2.9672 (3.0684)\tTop-5 Accuracy 79.063 (78.261)\n",
      "Epoch: [4][12400/17702]\tBatch Time 1.125 (1.097)\tData Load Time 0.359 (0.380)\tLoss 2.8994 (3.0685)\tTop-5 Accuracy 82.258 (78.263)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][12600/17702]\tBatch Time 1.062 (1.097)\tData Load Time 0.359 (0.380)\tLoss 3.0545 (3.0689)\tTop-5 Accuracy 77.008 (78.259)\n",
      "Epoch: [4][12800/17702]\tBatch Time 1.031 (1.096)\tData Load Time 0.328 (0.380)\tLoss 3.0507 (3.0686)\tTop-5 Accuracy 76.944 (78.263)\n",
      "Epoch: [4][13000/17702]\tBatch Time 1.203 (1.096)\tData Load Time 0.469 (0.379)\tLoss 3.0377 (3.0689)\tTop-5 Accuracy 78.670 (78.257)\n",
      "Epoch: [4][13200/17702]\tBatch Time 1.156 (1.096)\tData Load Time 0.391 (0.379)\tLoss 3.0287 (3.0690)\tTop-5 Accuracy 78.713 (78.259)\n",
      "Epoch: [4][13400/17702]\tBatch Time 1.000 (1.095)\tData Load Time 0.328 (0.379)\tLoss 3.4252 (3.0692)\tTop-5 Accuracy 73.458 (78.258)\n",
      "Epoch: [4][13600/17702]\tBatch Time 1.516 (1.095)\tData Load Time 0.422 (0.378)\tLoss 3.4462 (3.0695)\tTop-5 Accuracy 77.078 (78.254)\n",
      "Epoch: [4][13800/17702]\tBatch Time 0.953 (1.094)\tData Load Time 0.297 (0.378)\tLoss 3.1200 (3.0694)\tTop-5 Accuracy 75.931 (78.256)\n",
      "Epoch: [4][14000/17702]\tBatch Time 1.062 (1.094)\tData Load Time 0.391 (0.378)\tLoss 3.1111 (3.0694)\tTop-5 Accuracy 77.500 (78.257)\n",
      "Epoch: [4][14200/17702]\tBatch Time 1.094 (1.094)\tData Load Time 0.406 (0.377)\tLoss 3.0705 (3.0697)\tTop-5 Accuracy 78.431 (78.253)\n",
      "Epoch: [4][14400/17702]\tBatch Time 1.125 (1.094)\tData Load Time 0.344 (0.377)\tLoss 3.1625 (3.0695)\tTop-5 Accuracy 78.415 (78.255)\n",
      "Epoch: [4][14600/17702]\tBatch Time 1.172 (1.094)\tData Load Time 0.422 (0.377)\tLoss 2.9038 (3.0699)\tTop-5 Accuracy 81.201 (78.253)\n",
      "Epoch: [4][14800/17702]\tBatch Time 1.078 (1.094)\tData Load Time 0.406 (0.377)\tLoss 3.0646 (3.0702)\tTop-5 Accuracy 78.933 (78.250)\n",
      "Epoch: [4][15000/17702]\tBatch Time 1.109 (1.094)\tData Load Time 0.406 (0.377)\tLoss 2.8926 (3.0706)\tTop-5 Accuracy 82.097 (78.247)\n",
      "Epoch: [4][15200/17702]\tBatch Time 0.984 (1.093)\tData Load Time 0.281 (0.376)\tLoss 2.9962 (3.0707)\tTop-5 Accuracy 78.693 (78.247)\n",
      "Epoch: [4][15400/17702]\tBatch Time 1.125 (1.093)\tData Load Time 0.391 (0.376)\tLoss 3.0850 (3.0710)\tTop-5 Accuracy 79.032 (78.243)\n",
      "Epoch: [4][15600/17702]\tBatch Time 1.016 (1.093)\tData Load Time 0.344 (0.376)\tLoss 2.9611 (3.0709)\tTop-5 Accuracy 81.283 (78.245)\n",
      "Epoch: [4][15800/17702]\tBatch Time 1.172 (1.093)\tData Load Time 0.406 (0.376)\tLoss 3.4906 (3.0709)\tTop-5 Accuracy 71.467 (78.242)\n",
      "Epoch: [4][16000/17702]\tBatch Time 1.000 (1.093)\tData Load Time 0.312 (0.376)\tLoss 3.1144 (3.0711)\tTop-5 Accuracy 78.342 (78.240)\n",
      "Epoch: [4][16200/17702]\tBatch Time 0.984 (1.093)\tData Load Time 0.312 (0.376)\tLoss 2.8440 (3.0713)\tTop-5 Accuracy 82.548 (78.239)\n",
      "Epoch: [4][16400/17702]\tBatch Time 1.109 (1.092)\tData Load Time 0.344 (0.375)\tLoss 3.1055 (3.0715)\tTop-5 Accuracy 78.877 (78.238)\n",
      "Epoch: [4][16600/17702]\tBatch Time 1.109 (1.092)\tData Load Time 0.406 (0.375)\tLoss 3.4883 (3.0718)\tTop-5 Accuracy 73.130 (78.231)\n",
      "Epoch: [4][16800/17702]\tBatch Time 1.094 (1.092)\tData Load Time 0.375 (0.375)\tLoss 2.8254 (3.0720)\tTop-5 Accuracy 81.303 (78.231)\n",
      "Epoch: [4][17000/17702]\tBatch Time 7.125 (1.096)\tData Load Time 6.453 (0.379)\tLoss 3.0138 (3.0722)\tTop-5 Accuracy 78.670 (78.229)\n",
      "Epoch: [4][17200/17702]\tBatch Time 1.062 (1.103)\tData Load Time 0.344 (0.386)\tLoss 3.0018 (3.0723)\tTop-5 Accuracy 77.437 (78.227)\n",
      "Epoch: [4][17400/17702]\tBatch Time 1.047 (1.103)\tData Load Time 0.344 (0.386)\tLoss 3.3078 (3.0726)\tTop-5 Accuracy 72.776 (78.225)\n",
      "Epoch: [4][17600/17702]\tBatch Time 1.078 (1.103)\tData Load Time 0.422 (0.386)\tLoss 3.4029 (3.0728)\tTop-5 Accuracy 74.659 (78.222)\n",
      "Validation: [0/782]\tBatch Time 0.625 (0.625)\tLoss 2.8724 (2.8724)\tTop-5 Accuracy 81.073 (81.073)\t\n",
      "Validation: [200/782]\tBatch Time 0.437 (0.471)\tLoss 3.4252 (3.1629)\tTop-5 Accuracy 73.046 (76.895)\t\n",
      "Validation: [400/782]\tBatch Time 0.312 (0.415)\tLoss 3.1317 (3.1500)\tTop-5 Accuracy 74.725 (77.068)\t\n",
      "Validation: [600/782]\tBatch Time 0.281 (0.381)\tLoss 3.0060 (3.1518)\tTop-5 Accuracy 77.067 (76.977)\t\n",
      "\n",
      " * LOSS - 3.155, TOP-5 ACCURACY - 76.915, BLEU-4 - 0.23766805742384273\n",
      "\n",
      "Epoch: [5][0/17702]\tBatch Time 3.234 (3.234)\tData Load Time 2.109 (2.109)\tLoss 2.9483 (2.9483)\tTop-5 Accuracy 79.494 (79.494)\n",
      "Epoch: [5][200/17702]\tBatch Time 1.141 (1.148)\tData Load Time 0.453 (0.432)\tLoss 2.7774 (2.9759)\tTop-5 Accuracy 82.400 (79.519)\n",
      "Epoch: [5][400/17702]\tBatch Time 1.114 (1.134)\tData Load Time 0.453 (0.421)\tLoss 2.8800 (2.9737)\tTop-5 Accuracy 78.814 (79.507)\n",
      "Epoch: [5][600/17702]\tBatch Time 1.062 (1.135)\tData Load Time 0.391 (0.420)\tLoss 3.0764 (2.9855)\tTop-5 Accuracy 78.431 (79.303)\n",
      "Epoch: [5][800/17702]\tBatch Time 1.266 (1.132)\tData Load Time 0.437 (0.417)\tLoss 3.0787 (2.9883)\tTop-5 Accuracy 78.016 (79.284)\n",
      "Epoch: [5][1000/17702]\tBatch Time 1.125 (1.134)\tData Load Time 0.406 (0.416)\tLoss 2.9509 (2.9871)\tTop-5 Accuracy 81.233 (79.296)\n",
      "Epoch: [5][1200/17702]\tBatch Time 1.250 (1.135)\tData Load Time 0.484 (0.417)\tLoss 2.9209 (2.9879)\tTop-5 Accuracy 80.874 (79.315)\n",
      "Epoch: [5][1400/17702]\tBatch Time 1.047 (1.136)\tData Load Time 0.375 (0.419)\tLoss 3.0801 (2.9879)\tTop-5 Accuracy 74.412 (79.289)\n",
      "Epoch: [5][1600/17702]\tBatch Time 1.062 (1.133)\tData Load Time 0.391 (0.416)\tLoss 2.8578 (2.9924)\tTop-5 Accuracy 81.402 (79.240)\n",
      "Epoch: [5][1800/17702]\tBatch Time 1.062 (1.129)\tData Load Time 0.344 (0.412)\tLoss 3.2518 (2.9930)\tTop-5 Accuracy 76.720 (79.237)\n",
      "Epoch: [5][2000/17702]\tBatch Time 0.969 (1.125)\tData Load Time 0.297 (0.409)\tLoss 2.9106 (2.9915)\tTop-5 Accuracy 79.070 (79.251)\n",
      "Epoch: [5][2200/17702]\tBatch Time 1.125 (1.123)\tData Load Time 0.391 (0.407)\tLoss 2.9591 (2.9924)\tTop-5 Accuracy 75.698 (79.237)\n",
      "Epoch: [5][2400/17702]\tBatch Time 1.031 (1.122)\tData Load Time 0.344 (0.406)\tLoss 2.9256 (2.9936)\tTop-5 Accuracy 77.311 (79.233)\n",
      "Epoch: [5][2600/17702]\tBatch Time 1.094 (1.120)\tData Load Time 0.406 (0.404)\tLoss 3.0337 (2.9941)\tTop-5 Accuracy 77.198 (79.232)\n",
      "Epoch: [5][2800/17702]\tBatch Time 1.016 (1.121)\tData Load Time 0.328 (0.404)\tLoss 2.8984 (2.9962)\tTop-5 Accuracy 83.651 (79.186)\n",
      "Epoch: [5][3000/17702]\tBatch Time 1.141 (1.119)\tData Load Time 0.391 (0.402)\tLoss 3.4001 (2.9950)\tTop-5 Accuracy 73.615 (79.209)\n",
      "Epoch: [5][3200/17702]\tBatch Time 1.156 (1.118)\tData Load Time 0.391 (0.400)\tLoss 3.2254 (2.9957)\tTop-5 Accuracy 78.364 (79.194)\n",
      "Epoch: [5][3400/17702]\tBatch Time 1.156 (1.117)\tData Load Time 0.406 (0.400)\tLoss 3.0706 (2.9970)\tTop-5 Accuracy 80.263 (79.184)\n",
      "Epoch: [5][3600/17702]\tBatch Time 1.141 (1.117)\tData Load Time 0.453 (0.399)\tLoss 2.9554 (2.9976)\tTop-5 Accuracy 79.726 (79.182)\n",
      "Epoch: [5][3800/17702]\tBatch Time 1.062 (1.116)\tData Load Time 0.359 (0.398)\tLoss 2.9601 (2.9985)\tTop-5 Accuracy 78.531 (79.176)\n",
      "Epoch: [5][4000/17702]\tBatch Time 1.469 (1.115)\tData Load Time 0.797 (0.397)\tLoss 3.0684 (2.9989)\tTop-5 Accuracy 81.250 (79.165)\n",
      "Epoch: [5][4200/17702]\tBatch Time 1.109 (1.114)\tData Load Time 0.359 (0.396)\tLoss 3.1744 (2.9993)\tTop-5 Accuracy 78.049 (79.153)\n",
      "Epoch: [5][4400/17702]\tBatch Time 0.953 (1.113)\tData Load Time 0.297 (0.395)\tLoss 3.0037 (2.9998)\tTop-5 Accuracy 78.151 (79.152)\n",
      "Epoch: [5][4600/17702]\tBatch Time 1.156 (1.112)\tData Load Time 0.484 (0.395)\tLoss 2.9782 (3.0004)\tTop-5 Accuracy 77.746 (79.147)\n",
      "Epoch: [5][4800/17702]\tBatch Time 1.141 (1.111)\tData Load Time 0.422 (0.394)\tLoss 2.9670 (3.0010)\tTop-5 Accuracy 77.513 (79.139)\n",
      "Epoch: [5][5000/17702]\tBatch Time 1.047 (1.111)\tData Load Time 0.375 (0.394)\tLoss 2.9488 (3.0016)\tTop-5 Accuracy 81.744 (79.131)\n",
      "Epoch: [5][5200/17702]\tBatch Time 1.172 (1.111)\tData Load Time 0.516 (0.394)\tLoss 2.7187 (3.0023)\tTop-5 Accuracy 83.425 (79.124)\n",
      "Epoch: [5][5400/17702]\tBatch Time 1.187 (1.110)\tData Load Time 0.406 (0.394)\tLoss 3.2216 (3.0025)\tTop-5 Accuracy 74.674 (79.121)\n",
      "Epoch: [5][5600/17702]\tBatch Time 1.062 (1.110)\tData Load Time 0.312 (0.393)\tLoss 3.1890 (3.0036)\tTop-5 Accuracy 76.705 (79.104)\n",
      "Epoch: [5][5800/17702]\tBatch Time 1.094 (1.109)\tData Load Time 0.328 (0.393)\tLoss 3.2788 (3.0041)\tTop-5 Accuracy 78.571 (79.095)\n",
      "Epoch: [5][6000/17702]\tBatch Time 1.219 (1.109)\tData Load Time 0.437 (0.392)\tLoss 2.8982 (3.0046)\tTop-5 Accuracy 80.109 (79.088)\n",
      "Epoch: [5][6200/17702]\tBatch Time 1.047 (1.108)\tData Load Time 0.359 (0.392)\tLoss 2.9777 (3.0052)\tTop-5 Accuracy 79.666 (79.081)\n",
      "Epoch: [5][6400/17702]\tBatch Time 1.125 (1.108)\tData Load Time 0.469 (0.392)\tLoss 3.1807 (3.0056)\tTop-5 Accuracy 76.860 (79.080)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][6600/17702]\tBatch Time 1.156 (1.108)\tData Load Time 0.406 (0.391)\tLoss 3.0694 (3.0064)\tTop-5 Accuracy 76.336 (79.078)\n",
      "Epoch: [5][6800/17702]\tBatch Time 1.047 (1.108)\tData Load Time 0.391 (0.391)\tLoss 3.1284 (3.0075)\tTop-5 Accuracy 77.557 (79.063)\n",
      "Epoch: [5][7000/17702]\tBatch Time 1.125 (1.107)\tData Load Time 0.359 (0.391)\tLoss 2.7860 (3.0073)\tTop-5 Accuracy 83.511 (79.067)\n",
      "Epoch: [5][7200/17702]\tBatch Time 1.125 (1.107)\tData Load Time 0.375 (0.390)\tLoss 3.1335 (3.0076)\tTop-5 Accuracy 77.394 (79.062)\n",
      "Epoch: [5][7400/17702]\tBatch Time 1.219 (1.107)\tData Load Time 0.531 (0.390)\tLoss 2.9187 (3.0078)\tTop-5 Accuracy 80.172 (79.060)\n",
      "Epoch: [5][7600/17702]\tBatch Time 1.031 (1.107)\tData Load Time 0.344 (0.390)\tLoss 3.1439 (3.0081)\tTop-5 Accuracy 75.871 (79.059)\n",
      "Epoch: [5][7800/17702]\tBatch Time 1.109 (1.107)\tData Load Time 0.375 (0.390)\tLoss 2.9092 (3.0086)\tTop-5 Accuracy 81.267 (79.053)\n",
      "Epoch: [5][8000/17702]\tBatch Time 1.297 (1.107)\tData Load Time 0.484 (0.390)\tLoss 3.1913 (3.0093)\tTop-5 Accuracy 79.540 (79.046)\n",
      "Epoch: [5][8200/17702]\tBatch Time 1.109 (1.107)\tData Load Time 0.422 (0.390)\tLoss 3.1681 (3.0093)\tTop-5 Accuracy 77.838 (79.044)\n",
      "Epoch: [5][8400/17702]\tBatch Time 1.047 (1.107)\tData Load Time 0.375 (0.390)\tLoss 2.7823 (3.0094)\tTop-5 Accuracy 82.386 (79.045)\n",
      "Epoch: [5][8600/17702]\tBatch Time 1.062 (1.106)\tData Load Time 0.375 (0.390)\tLoss 2.6929 (3.0095)\tTop-5 Accuracy 83.427 (79.049)\n",
      "Epoch: [5][8800/17702]\tBatch Time 1.062 (1.106)\tData Load Time 0.406 (0.390)\tLoss 2.9007 (3.0096)\tTop-5 Accuracy 80.851 (79.048)\n",
      "Epoch: [5][9000/17702]\tBatch Time 1.094 (1.106)\tData Load Time 0.406 (0.389)\tLoss 3.2869 (3.0102)\tTop-5 Accuracy 75.824 (79.042)\n",
      "Epoch: [5][9200/17702]\tBatch Time 1.047 (1.106)\tData Load Time 0.375 (0.389)\tLoss 3.3466 (3.0107)\tTop-5 Accuracy 73.295 (79.042)\n",
      "Epoch: [5][9400/17702]\tBatch Time 1.094 (1.106)\tData Load Time 0.375 (0.390)\tLoss 3.4735 (3.0112)\tTop-5 Accuracy 71.781 (79.035)\n",
      "Epoch: [5][9600/17702]\tBatch Time 1.047 (1.106)\tData Load Time 0.375 (0.389)\tLoss 2.6790 (3.0117)\tTop-5 Accuracy 83.908 (79.028)\n",
      "Epoch: [5][9800/17702]\tBatch Time 1.141 (1.105)\tData Load Time 0.422 (0.389)\tLoss 2.7348 (3.0122)\tTop-5 Accuracy 81.283 (79.022)\n",
      "Epoch: [5][10000/17702]\tBatch Time 1.094 (1.105)\tData Load Time 0.406 (0.389)\tLoss 2.9421 (3.0127)\tTop-5 Accuracy 77.632 (79.015)\n",
      "Epoch: [5][10200/17702]\tBatch Time 1.062 (1.105)\tData Load Time 0.391 (0.389)\tLoss 3.4329 (3.0129)\tTop-5 Accuracy 70.263 (79.012)\n",
      "Epoch: [5][10400/17702]\tBatch Time 1.016 (1.105)\tData Load Time 0.359 (0.388)\tLoss 3.0418 (3.0129)\tTop-5 Accuracy 79.050 (79.010)\n",
      "Epoch: [5][10600/17702]\tBatch Time 1.047 (1.104)\tData Load Time 0.359 (0.388)\tLoss 2.9177 (3.0131)\tTop-5 Accuracy 80.000 (79.012)\n",
      "Epoch: [5][10800/17702]\tBatch Time 1.141 (1.104)\tData Load Time 0.391 (0.388)\tLoss 2.9271 (3.0132)\tTop-5 Accuracy 80.278 (79.011)\n",
      "Epoch: [5][11000/17702]\tBatch Time 1.078 (1.104)\tData Load Time 0.406 (0.388)\tLoss 3.0738 (3.0135)\tTop-5 Accuracy 76.218 (79.007)\n",
      "Epoch: [5][11200/17702]\tBatch Time 1.094 (1.104)\tData Load Time 0.359 (0.388)\tLoss 3.2293 (3.0142)\tTop-5 Accuracy 75.773 (79.000)\n",
      "Epoch: [5][11400/17702]\tBatch Time 1.078 (1.104)\tData Load Time 0.359 (0.388)\tLoss 3.0689 (3.0143)\tTop-5 Accuracy 78.552 (78.999)\n",
      "Epoch: [5][11600/17702]\tBatch Time 0.969 (1.103)\tData Load Time 0.266 (0.387)\tLoss 2.8492 (3.0144)\tTop-5 Accuracy 78.571 (78.998)\n",
      "Epoch: [5][11800/17702]\tBatch Time 1.078 (1.103)\tData Load Time 0.406 (0.388)\tLoss 3.1345 (3.0151)\tTop-5 Accuracy 76.420 (78.991)\n",
      "Epoch: [5][12000/17702]\tBatch Time 1.156 (1.103)\tData Load Time 0.469 (0.388)\tLoss 3.1422 (3.0154)\tTop-5 Accuracy 79.370 (78.988)\n",
      "Epoch: [5][12200/17702]\tBatch Time 1.031 (1.103)\tData Load Time 0.344 (0.387)\tLoss 2.8830 (3.0156)\tTop-5 Accuracy 80.541 (78.984)\n",
      "Epoch: [5][12400/17702]\tBatch Time 1.047 (1.103)\tData Load Time 0.359 (0.387)\tLoss 2.7454 (3.0159)\tTop-5 Accuracy 83.243 (78.981)\n",
      "Epoch: [5][12600/17702]\tBatch Time 1.094 (1.103)\tData Load Time 0.359 (0.387)\tLoss 2.7999 (3.0165)\tTop-5 Accuracy 81.402 (78.975)\n",
      "Epoch: [5][12800/17702]\tBatch Time 1.000 (1.103)\tData Load Time 0.297 (0.387)\tLoss 3.1031 (3.0165)\tTop-5 Accuracy 78.273 (78.972)\n",
      "Epoch: [5][13000/17702]\tBatch Time 1.094 (1.103)\tData Load Time 0.359 (0.388)\tLoss 3.0089 (3.0166)\tTop-5 Accuracy 78.297 (78.973)\n",
      "Epoch: [5][13200/17702]\tBatch Time 1.141 (1.104)\tData Load Time 0.406 (0.388)\tLoss 2.7859 (3.0170)\tTop-5 Accuracy 83.690 (78.970)\n",
      "Epoch: [5][13400/17702]\tBatch Time 1.141 (1.105)\tData Load Time 0.391 (0.389)\tLoss 3.3337 (3.0170)\tTop-5 Accuracy 74.373 (78.969)\n",
      "Epoch: [5][13600/17702]\tBatch Time 1.047 (1.105)\tData Load Time 0.328 (0.389)\tLoss 3.0471 (3.0171)\tTop-5 Accuracy 76.596 (78.969)\n",
      "Epoch: [5][13800/17702]\tBatch Time 1.031 (1.104)\tData Load Time 0.328 (0.389)\tLoss 2.8646 (3.0174)\tTop-5 Accuracy 81.742 (78.967)\n",
      "Epoch: [5][14000/17702]\tBatch Time 1.141 (1.104)\tData Load Time 0.422 (0.389)\tLoss 3.2349 (3.0173)\tTop-5 Accuracy 76.942 (78.970)\n",
      "Epoch: [5][14200/17702]\tBatch Time 1.094 (1.104)\tData Load Time 0.391 (0.389)\tLoss 3.2184 (3.0175)\tTop-5 Accuracy 76.471 (78.968)\n",
      "Epoch: [5][14400/17702]\tBatch Time 1.094 (1.104)\tData Load Time 0.406 (0.388)\tLoss 3.1834 (3.0181)\tTop-5 Accuracy 75.332 (78.958)\n",
      "Epoch: [5][14600/17702]\tBatch Time 1.156 (1.104)\tData Load Time 0.375 (0.388)\tLoss 3.0137 (3.0186)\tTop-5 Accuracy 79.630 (78.953)\n",
      "Epoch: [5][14800/17702]\tBatch Time 1.000 (1.103)\tData Load Time 0.297 (0.388)\tLoss 3.0696 (3.0189)\tTop-5 Accuracy 76.923 (78.950)\n",
      "Epoch: [5][15000/17702]\tBatch Time 1.078 (1.103)\tData Load Time 0.391 (0.388)\tLoss 2.8263 (3.0191)\tTop-5 Accuracy 82.210 (78.948)\n",
      "Epoch: [5][15200/17702]\tBatch Time 1.109 (1.103)\tData Load Time 0.453 (0.388)\tLoss 2.9621 (3.0193)\tTop-5 Accuracy 79.420 (78.948)\n",
      "Epoch: [5][15400/17702]\tBatch Time 1.109 (1.103)\tData Load Time 0.406 (0.387)\tLoss 2.9248 (3.0195)\tTop-5 Accuracy 79.282 (78.943)\n",
      "Epoch: [5][15600/17702]\tBatch Time 1.094 (1.102)\tData Load Time 0.422 (0.387)\tLoss 3.1612 (3.0195)\tTop-5 Accuracy 78.022 (78.946)\n",
      "Epoch: [5][15800/17702]\tBatch Time 1.031 (1.102)\tData Load Time 0.328 (0.387)\tLoss 3.0383 (3.0199)\tTop-5 Accuracy 81.111 (78.941)\n",
      "Epoch: [5][16000/17702]\tBatch Time 1.094 (1.102)\tData Load Time 0.422 (0.387)\tLoss 3.0754 (3.0204)\tTop-5 Accuracy 76.359 (78.938)\n",
      "Epoch: [5][16200/17702]\tBatch Time 1.203 (1.102)\tData Load Time 0.453 (0.387)\tLoss 3.0171 (3.0207)\tTop-5 Accuracy 80.157 (78.935)\n",
      "Epoch: [5][16400/17702]\tBatch Time 1.094 (1.102)\tData Load Time 0.391 (0.387)\tLoss 2.8582 (3.0211)\tTop-5 Accuracy 80.056 (78.930)\n",
      "Epoch: [5][16600/17702]\tBatch Time 1.219 (1.102)\tData Load Time 0.375 (0.387)\tLoss 3.0878 (3.0212)\tTop-5 Accuracy 77.202 (78.929)\n",
      "Epoch: [5][16800/17702]\tBatch Time 1.109 (1.102)\tData Load Time 0.453 (0.386)\tLoss 2.7967 (3.0214)\tTop-5 Accuracy 82.336 (78.927)\n",
      "Epoch: [5][17000/17702]\tBatch Time 1.141 (1.101)\tData Load Time 0.375 (0.386)\tLoss 3.2214 (3.0217)\tTop-5 Accuracy 74.394 (78.923)\n",
      "Epoch: [5][17200/17702]\tBatch Time 1.109 (1.101)\tData Load Time 0.359 (0.386)\tLoss 3.1098 (3.0221)\tTop-5 Accuracy 77.067 (78.917)\n",
      "Epoch: [5][17400/17702]\tBatch Time 1.172 (1.101)\tData Load Time 0.469 (0.385)\tLoss 3.1395 (3.0220)\tTop-5 Accuracy 78.889 (78.918)\n",
      "Epoch: [5][17600/17702]\tBatch Time 1.031 (1.100)\tData Load Time 0.328 (0.385)\tLoss 3.2242 (3.0219)\tTop-5 Accuracy 78.363 (78.920)\n",
      "Validation: [0/782]\tBatch Time 0.547 (0.547)\tLoss 2.9636 (2.9636)\tTop-5 Accuracy 78.763 (78.763)\t\n",
      "Validation: [200/782]\tBatch Time 0.344 (0.467)\tLoss 3.2948 (3.1664)\tTop-5 Accuracy 75.978 (76.861)\t\n",
      "Validation: [400/782]\tBatch Time 0.281 (0.409)\tLoss 3.0155 (3.1511)\tTop-5 Accuracy 78.310 (77.034)\t\n",
      "Validation: [600/782]\tBatch Time 0.328 (0.379)\tLoss 2.9817 (3.1460)\tTop-5 Accuracy 78.533 (77.082)\t\n",
      "\n",
      " * LOSS - 3.152, TOP-5 ACCURACY - 77.024, BLEU-4 - 0.23992384141514403\n",
      "\n",
      "Epoch: [6][0/17702]\tBatch Time 2.626 (2.626)\tData Load Time 1.923 (1.923)\tLoss 2.6703 (2.6703)\tTop-5 Accuracy 81.972 (81.972)\n",
      "Epoch: [6][200/17702]\tBatch Time 1.172 (1.132)\tData Load Time 0.391 (0.419)\tLoss 2.7973 (2.9376)\tTop-5 Accuracy 81.452 (79.911)\n",
      "Epoch: [6][400/17702]\tBatch Time 1.031 (1.118)\tData Load Time 0.391 (0.404)\tLoss 2.6704 (2.9350)\tTop-5 Accuracy 82.584 (79.947)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][600/17702]\tBatch Time 1.078 (1.113)\tData Load Time 0.375 (0.401)\tLoss 2.7387 (2.9278)\tTop-5 Accuracy 83.161 (80.097)\n",
      "Epoch: [6][800/17702]\tBatch Time 1.109 (1.112)\tData Load Time 0.422 (0.401)\tLoss 2.7227 (2.9276)\tTop-5 Accuracy 84.426 (80.129)\n",
      "Epoch: [6][1000/17702]\tBatch Time 1.266 (1.112)\tData Load Time 0.484 (0.401)\tLoss 2.9361 (2.9319)\tTop-5 Accuracy 79.082 (80.070)\n",
      "Epoch: [6][1200/17702]\tBatch Time 1.359 (1.118)\tData Load Time 0.687 (0.406)\tLoss 2.9906 (2.9369)\tTop-5 Accuracy 79.006 (80.023)\n",
      "Epoch: [6][1400/17702]\tBatch Time 1.094 (1.118)\tData Load Time 0.422 (0.406)\tLoss 2.9327 (2.9392)\tTop-5 Accuracy 78.223 (79.981)\n",
      "Epoch: [6][1600/17702]\tBatch Time 1.078 (1.118)\tData Load Time 0.375 (0.405)\tLoss 2.9290 (2.9403)\tTop-5 Accuracy 79.144 (79.958)\n",
      "Epoch: [6][1800/17702]\tBatch Time 1.000 (1.116)\tData Load Time 0.328 (0.403)\tLoss 2.7221 (2.9404)\tTop-5 Accuracy 84.718 (79.954)\n",
      "Epoch: [6][2000/17702]\tBatch Time 1.125 (1.113)\tData Load Time 0.500 (0.400)\tLoss 2.8470 (2.9418)\tTop-5 Accuracy 78.963 (79.932)\n",
      "Epoch: [6][2200/17702]\tBatch Time 1.031 (1.110)\tData Load Time 0.359 (0.397)\tLoss 2.8758 (2.9425)\tTop-5 Accuracy 81.892 (79.933)\n",
      "Epoch: [6][2400/17702]\tBatch Time 1.125 (1.107)\tData Load Time 0.391 (0.395)\tLoss 2.7215 (2.9428)\tTop-5 Accuracy 82.967 (79.936)\n",
      "Epoch: [6][2600/17702]\tBatch Time 1.078 (1.106)\tData Load Time 0.297 (0.393)\tLoss 2.8594 (2.9445)\tTop-5 Accuracy 82.171 (79.918)\n",
      "Epoch: [6][2800/17702]\tBatch Time 1.078 (1.103)\tData Load Time 0.359 (0.391)\tLoss 2.9810 (2.9429)\tTop-5 Accuracy 77.688 (79.929)\n",
      "Epoch: [6][3000/17702]\tBatch Time 1.000 (1.101)\tData Load Time 0.375 (0.389)\tLoss 3.2178 (2.9436)\tTop-5 Accuracy 76.418 (79.924)\n",
      "Epoch: [6][3200/17702]\tBatch Time 1.094 (1.101)\tData Load Time 0.375 (0.388)\tLoss 3.0328 (2.9457)\tTop-5 Accuracy 78.158 (79.900)\n",
      "Epoch: [6][3400/17702]\tBatch Time 1.016 (1.099)\tData Load Time 0.328 (0.387)\tLoss 2.9917 (2.9469)\tTop-5 Accuracy 77.095 (79.876)\n",
      "Epoch: [6][3600/17702]\tBatch Time 1.125 (1.099)\tData Load Time 0.344 (0.386)\tLoss 2.9983 (2.9473)\tTop-5 Accuracy 78.284 (79.877)\n",
      "Epoch: [6][3800/17702]\tBatch Time 1.094 (1.098)\tData Load Time 0.344 (0.385)\tLoss 3.0824 (2.9478)\tTop-5 Accuracy 77.901 (79.881)\n",
      "Epoch: [6][4000/17702]\tBatch Time 1.016 (1.097)\tData Load Time 0.344 (0.384)\tLoss 3.1046 (2.9490)\tTop-5 Accuracy 76.404 (79.860)\n",
      "Epoch: [6][4200/17702]\tBatch Time 1.156 (1.096)\tData Load Time 0.453 (0.383)\tLoss 3.1766 (2.9494)\tTop-5 Accuracy 77.419 (79.858)\n",
      "Epoch: [6][4400/17702]\tBatch Time 1.078 (1.095)\tData Load Time 0.375 (0.383)\tLoss 2.9836 (2.9498)\tTop-5 Accuracy 79.459 (79.855)\n",
      "Epoch: [6][4600/17702]\tBatch Time 1.094 (1.094)\tData Load Time 0.453 (0.382)\tLoss 2.5828 (2.9505)\tTop-5 Accuracy 84.000 (79.849)\n",
      "Epoch: [6][4800/17702]\tBatch Time 1.094 (1.094)\tData Load Time 0.344 (0.382)\tLoss 3.0131 (2.9511)\tTop-5 Accuracy 77.694 (79.842)\n",
      "Epoch: [6][5000/17702]\tBatch Time 1.094 (1.093)\tData Load Time 0.281 (0.381)\tLoss 3.1789 (2.9514)\tTop-5 Accuracy 76.883 (79.841)\n",
      "Epoch: [6][5200/17702]\tBatch Time 1.109 (1.093)\tData Load Time 0.422 (0.381)\tLoss 2.7672 (2.9516)\tTop-5 Accuracy 81.232 (79.840)\n",
      "Epoch: [6][5400/17702]\tBatch Time 1.062 (1.092)\tData Load Time 0.375 (0.380)\tLoss 3.1092 (2.9524)\tTop-5 Accuracy 77.540 (79.825)\n",
      "Epoch: [6][5600/17702]\tBatch Time 1.094 (1.092)\tData Load Time 0.359 (0.380)\tLoss 2.8805 (2.9525)\tTop-5 Accuracy 80.501 (79.832)\n",
      "Epoch: [6][5800/17702]\tBatch Time 1.172 (1.092)\tData Load Time 0.391 (0.379)\tLoss 2.7816 (2.9536)\tTop-5 Accuracy 81.638 (79.819)\n",
      "Epoch: [6][6000/17702]\tBatch Time 1.312 (1.092)\tData Load Time 0.578 (0.380)\tLoss 2.9433 (2.9542)\tTop-5 Accuracy 80.376 (79.813)\n",
      "Epoch: [6][6200/17702]\tBatch Time 1.078 (1.092)\tData Load Time 0.344 (0.380)\tLoss 3.3090 (2.9551)\tTop-5 Accuracy 76.127 (79.799)\n",
      "Epoch: [6][6400/17702]\tBatch Time 1.078 (1.091)\tData Load Time 0.406 (0.380)\tLoss 2.9321 (2.9552)\tTop-5 Accuracy 80.056 (79.795)\n",
      "Epoch: [6][6600/17702]\tBatch Time 1.109 (1.091)\tData Load Time 0.344 (0.379)\tLoss 3.0454 (2.9561)\tTop-5 Accuracy 78.495 (79.779)\n",
      "Epoch: [6][6800/17702]\tBatch Time 1.125 (1.091)\tData Load Time 0.375 (0.379)\tLoss 3.1092 (2.9563)\tTop-5 Accuracy 77.984 (79.778)\n",
      "Epoch: [6][7000/17702]\tBatch Time 1.156 (1.091)\tData Load Time 0.391 (0.379)\tLoss 2.9857 (2.9564)\tTop-5 Accuracy 78.904 (79.779)\n",
      "Epoch: [6][7200/17702]\tBatch Time 1.031 (1.090)\tData Load Time 0.328 (0.379)\tLoss 3.0770 (2.9568)\tTop-5 Accuracy 78.261 (79.771)\n",
      "Epoch: [6][7400/17702]\tBatch Time 1.062 (1.090)\tData Load Time 0.359 (0.378)\tLoss 2.8781 (2.9573)\tTop-5 Accuracy 80.749 (79.766)\n",
      "Epoch: [6][7600/17702]\tBatch Time 1.078 (1.090)\tData Load Time 0.391 (0.378)\tLoss 3.0508 (2.9578)\tTop-5 Accuracy 78.820 (79.756)\n",
      "Epoch: [6][7800/17702]\tBatch Time 1.094 (1.089)\tData Load Time 0.406 (0.378)\tLoss 2.9155 (2.9587)\tTop-5 Accuracy 80.609 (79.747)\n",
      "Epoch: [6][8000/17702]\tBatch Time 1.078 (1.089)\tData Load Time 0.422 (0.378)\tLoss 2.8675 (2.9590)\tTop-5 Accuracy 82.235 (79.743)\n",
      "Epoch: [6][8200/17702]\tBatch Time 1.125 (1.089)\tData Load Time 0.437 (0.378)\tLoss 2.8699 (2.9591)\tTop-5 Accuracy 80.332 (79.739)\n",
      "Epoch: [6][8400/17702]\tBatch Time 1.125 (1.090)\tData Load Time 0.375 (0.378)\tLoss 3.1564 (2.9600)\tTop-5 Accuracy 79.275 (79.729)\n",
      "Epoch: [6][8600/17702]\tBatch Time 1.109 (1.090)\tData Load Time 0.344 (0.378)\tLoss 2.7373 (2.9606)\tTop-5 Accuracy 81.795 (79.722)\n",
      "Epoch: [6][8800/17702]\tBatch Time 1.047 (1.089)\tData Load Time 0.344 (0.378)\tLoss 3.0194 (2.9610)\tTop-5 Accuracy 79.178 (79.717)\n",
      "Epoch: [6][9000/17702]\tBatch Time 1.078 (1.089)\tData Load Time 0.406 (0.377)\tLoss 2.7928 (2.9617)\tTop-5 Accuracy 81.543 (79.706)\n",
      "Epoch: [6][9200/17702]\tBatch Time 1.078 (1.089)\tData Load Time 0.391 (0.378)\tLoss 2.8600 (2.9620)\tTop-5 Accuracy 81.356 (79.705)\n",
      "Epoch: [6][9400/17702]\tBatch Time 1.266 (1.090)\tData Load Time 0.375 (0.378)\tLoss 2.9206 (2.9624)\tTop-5 Accuracy 78.906 (79.701)\n",
      "Epoch: [6][9600/17702]\tBatch Time 1.047 (1.090)\tData Load Time 0.359 (0.378)\tLoss 2.7994 (2.9631)\tTop-5 Accuracy 82.682 (79.692)\n",
      "Epoch: [6][9800/17702]\tBatch Time 1.031 (1.090)\tData Load Time 0.344 (0.378)\tLoss 2.7252 (2.9633)\tTop-5 Accuracy 83.106 (79.693)\n",
      "Epoch: [6][10000/17702]\tBatch Time 1.078 (1.090)\tData Load Time 0.328 (0.378)\tLoss 3.3710 (2.9637)\tTop-5 Accuracy 78.202 (79.691)\n",
      "Epoch: [6][10200/17702]\tBatch Time 1.172 (1.090)\tData Load Time 0.391 (0.378)\tLoss 2.6726 (2.9641)\tTop-5 Accuracy 84.741 (79.687)\n",
      "Epoch: [6][10400/17702]\tBatch Time 1.000 (1.090)\tData Load Time 0.359 (0.378)\tLoss 2.7941 (2.9649)\tTop-5 Accuracy 81.742 (79.677)\n",
      "Epoch: [6][10600/17702]\tBatch Time 1.016 (1.090)\tData Load Time 0.328 (0.378)\tLoss 2.9007 (2.9649)\tTop-5 Accuracy 78.904 (79.678)\n",
      "Epoch: [6][10800/17702]\tBatch Time 1.094 (1.091)\tData Load Time 0.375 (0.378)\tLoss 3.0069 (2.9657)\tTop-5 Accuracy 79.722 (79.668)\n",
      "Epoch: [6][11000/17702]\tBatch Time 1.187 (1.091)\tData Load Time 0.344 (0.378)\tLoss 3.2745 (2.9663)\tTop-5 Accuracy 76.190 (79.659)\n",
      "Epoch: [6][11200/17702]\tBatch Time 1.391 (1.091)\tData Load Time 0.469 (0.378)\tLoss 3.0149 (2.9670)\tTop-5 Accuracy 79.028 (79.654)\n",
      "Epoch: [6][11400/17702]\tBatch Time 1.750 (1.091)\tData Load Time 1.047 (0.378)\tLoss 3.0568 (2.9675)\tTop-5 Accuracy 77.650 (79.649)\n",
      "Epoch: [6][11600/17702]\tBatch Time 1.094 (1.091)\tData Load Time 0.359 (0.378)\tLoss 2.9509 (2.9682)\tTop-5 Accuracy 79.630 (79.638)\n",
      "Epoch: [6][11800/17702]\tBatch Time 1.234 (1.091)\tData Load Time 0.391 (0.378)\tLoss 2.8162 (2.9686)\tTop-5 Accuracy 81.868 (79.632)\n",
      "Epoch: [6][12000/17702]\tBatch Time 1.219 (1.091)\tData Load Time 0.391 (0.378)\tLoss 3.1328 (2.9691)\tTop-5 Accuracy 78.149 (79.626)\n",
      "Epoch: [6][12200/17702]\tBatch Time 1.078 (1.091)\tData Load Time 0.375 (0.378)\tLoss 3.0308 (2.9689)\tTop-5 Accuracy 75.910 (79.629)\n",
      "Epoch: [6][12400/17702]\tBatch Time 1.062 (1.091)\tData Load Time 0.344 (0.378)\tLoss 2.9956 (2.9692)\tTop-5 Accuracy 80.697 (79.628)\n",
      "Epoch: [6][12600/17702]\tBatch Time 1.187 (1.091)\tData Load Time 0.562 (0.378)\tLoss 3.2312 (2.9695)\tTop-5 Accuracy 74.230 (79.625)\n",
      "Epoch: [6][12800/17702]\tBatch Time 1.062 (1.091)\tData Load Time 0.344 (0.378)\tLoss 2.9891 (2.9700)\tTop-5 Accuracy 78.591 (79.620)\n",
      "Epoch: [6][13000/17702]\tBatch Time 1.031 (1.091)\tData Load Time 0.391 (0.378)\tLoss 2.9474 (2.9703)\tTop-5 Accuracy 78.674 (79.617)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][13200/17702]\tBatch Time 1.094 (1.091)\tData Load Time 0.406 (0.378)\tLoss 3.3548 (2.9706)\tTop-5 Accuracy 74.359 (79.614)\n",
      "Epoch: [6][13400/17702]\tBatch Time 1.094 (1.091)\tData Load Time 0.312 (0.378)\tLoss 2.9509 (2.9706)\tTop-5 Accuracy 80.637 (79.614)\n",
      "Epoch: [6][13600/17702]\tBatch Time 1.109 (1.091)\tData Load Time 0.406 (0.378)\tLoss 3.1058 (2.9709)\tTop-5 Accuracy 76.519 (79.609)\n",
      "Epoch: [6][13800/17702]\tBatch Time 1.078 (1.091)\tData Load Time 0.375 (0.378)\tLoss 2.9133 (2.9713)\tTop-5 Accuracy 80.541 (79.603)\n",
      "Epoch: [6][14000/17702]\tBatch Time 1.078 (1.091)\tData Load Time 0.375 (0.378)\tLoss 3.0685 (2.9718)\tTop-5 Accuracy 78.992 (79.598)\n",
      "Epoch: [6][14200/17702]\tBatch Time 1.047 (1.091)\tData Load Time 0.328 (0.378)\tLoss 3.0349 (2.9720)\tTop-5 Accuracy 75.806 (79.596)\n",
      "Epoch: [6][14400/17702]\tBatch Time 1.078 (1.091)\tData Load Time 0.375 (0.378)\tLoss 3.3803 (2.9725)\tTop-5 Accuracy 72.576 (79.590)\n",
      "Epoch: [6][14600/17702]\tBatch Time 1.062 (1.091)\tData Load Time 0.359 (0.378)\tLoss 2.8036 (2.9728)\tTop-5 Accuracy 81.067 (79.587)\n",
      "Epoch: [6][14800/17702]\tBatch Time 1.141 (1.091)\tData Load Time 0.375 (0.378)\tLoss 3.0019 (2.9733)\tTop-5 Accuracy 77.684 (79.579)\n",
      "Epoch: [6][15000/17702]\tBatch Time 1.016 (1.091)\tData Load Time 0.281 (0.378)\tLoss 3.2276 (2.9737)\tTop-5 Accuracy 76.667 (79.575)\n",
      "Epoch: [6][15200/17702]\tBatch Time 1.156 (1.092)\tData Load Time 0.406 (0.379)\tLoss 3.3519 (2.9739)\tTop-5 Accuracy 74.870 (79.571)\n",
      "Epoch: [6][15400/17702]\tBatch Time 1.078 (1.094)\tData Load Time 0.391 (0.381)\tLoss 2.7727 (2.9741)\tTop-5 Accuracy 81.492 (79.569)\n",
      "Epoch: [6][15600/17702]\tBatch Time 1.062 (1.096)\tData Load Time 0.344 (0.382)\tLoss 3.0834 (2.9744)\tTop-5 Accuracy 78.608 (79.564)\n",
      "Epoch: [6][15800/17702]\tBatch Time 1.078 (1.095)\tData Load Time 0.391 (0.382)\tLoss 2.8891 (2.9747)\tTop-5 Accuracy 81.844 (79.560)\n",
      "Epoch: [6][16000/17702]\tBatch Time 1.094 (1.096)\tData Load Time 0.359 (0.382)\tLoss 2.9577 (2.9751)\tTop-5 Accuracy 81.572 (79.554)\n",
      "Epoch: [6][16200/17702]\tBatch Time 1.156 (1.096)\tData Load Time 0.344 (0.382)\tLoss 3.0130 (2.9755)\tTop-5 Accuracy 77.285 (79.551)\n",
      "Epoch: [6][16400/17702]\tBatch Time 1.109 (1.095)\tData Load Time 0.391 (0.381)\tLoss 2.9704 (2.9757)\tTop-5 Accuracy 79.570 (79.548)\n",
      "Epoch: [6][16600/17702]\tBatch Time 1.203 (1.095)\tData Load Time 0.469 (0.381)\tLoss 3.1927 (2.9761)\tTop-5 Accuracy 76.454 (79.544)\n",
      "Epoch: [6][16800/17702]\tBatch Time 1.031 (1.095)\tData Load Time 0.328 (0.381)\tLoss 3.0060 (2.9762)\tTop-5 Accuracy 78.237 (79.543)\n",
      "Epoch: [6][17000/17702]\tBatch Time 1.125 (1.095)\tData Load Time 0.391 (0.381)\tLoss 2.9544 (2.9765)\tTop-5 Accuracy 78.630 (79.540)\n",
      "Epoch: [6][17200/17702]\tBatch Time 0.969 (1.095)\tData Load Time 0.297 (0.381)\tLoss 3.1151 (2.9768)\tTop-5 Accuracy 78.797 (79.538)\n",
      "Epoch: [6][17400/17702]\tBatch Time 1.047 (1.095)\tData Load Time 0.375 (0.381)\tLoss 3.0235 (2.9772)\tTop-5 Accuracy 78.989 (79.534)\n",
      "Epoch: [6][17600/17702]\tBatch Time 1.141 (1.095)\tData Load Time 0.406 (0.381)\tLoss 3.1878 (2.9775)\tTop-5 Accuracy 73.629 (79.531)\n",
      "Validation: [0/782]\tBatch Time 0.547 (0.547)\tLoss 3.0591 (3.0591)\tTop-5 Accuracy 80.000 (80.000)\t\n",
      "Validation: [200/782]\tBatch Time 0.344 (0.483)\tLoss 3.4874 (3.1432)\tTop-5 Accuracy 72.928 (77.140)\t\n",
      "Validation: [400/782]\tBatch Time 0.312 (0.425)\tLoss 2.9102 (3.1534)\tTop-5 Accuracy 80.267 (76.991)\t\n",
      "Validation: [600/782]\tBatch Time 0.297 (0.390)\tLoss 3.2811 (3.1571)\tTop-5 Accuracy 72.581 (76.962)\t\n",
      "\n",
      " * LOSS - 3.149, TOP-5 ACCURACY - 77.102, BLEU-4 - 0.23877517316825472\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Epochs\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "        if fine_tune_encoder:\n",
    "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "          encoder=encoder,\n",
    "          decoder=decoder,\n",
    "          criterion=criterion,\n",
    "          encoder_optimizer=encoder_optimizer,\n",
    "          decoder_optimizer=decoder_optimizer,\n",
    "          epoch=epoch)\n",
    "\n",
    "    # One epoch's validation\n",
    "    recent_bleu4 = validate(val_loader=val_loader,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            criterion=criterion)\n",
    "\n",
    "    # Check if there was an improvement\n",
    "    is_best = recent_bleu4 > best_bleu4\n",
    "    best_bleu4 = max(recent_bleu4, best_bleu4)\n",
    "    if not is_best:\n",
    "        epochs_since_improvement += 1\n",
    "        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "    else:\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                    decoder_optimizer, recent_bleu4, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
