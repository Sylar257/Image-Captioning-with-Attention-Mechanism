{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Encoder-Decoder network with attention mechanism\n",
    "## Data preparation\n",
    "* Create our input files from the Microsoft COCO dataset.\n",
    "* By default COCO come with 5 captions per image. \n",
    "* We are going to ignore the captions that are longer than 50 words. As we have seen in the Image-Captioning-Project, they are really rare.\n",
    "* The output files are stored under the \"output_folder\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TRAIN images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 113287/113287 [48:08<00:00, 39.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading VAL images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [03:26<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TEST images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:57<00:00, 28.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import create_input_files\n",
    "\n",
    "# This will create big files in your computer.\n",
    "create_input_files(dataset='coco',\n",
    "                   karpathy_json_path='dataset_coco.json',\n",
    "                   image_folder='../cocoapi-master/images',\n",
    "                   captions_per_image=5,\n",
    "                   min_word_freq=5,\n",
    "                   output_folder='../cocoapi-master/images',\n",
    "                   max_len=50\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../cocoapi-master/images'         # the output_folder of created input_files\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq' # the same way we created them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import necessary packages\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 512         # dimension of word embeddings\n",
    "attention_dim = 512   # dimension of attention linear layers\n",
    "decoder_dim = 512     # dimention of LSTM decoder\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # GPU set for PyTorch\n",
    "cudnn.benchmark = True # set to \"True\" only if inputs to model are fixed size; otherwise lot of computational overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 3                    # Max number of training epochs if early-stopping is not triggered\n",
    "epochs_since_improvement = 0  # This tracks the number of epochs since the last improvement was made\n",
    "batch_size = 32\n",
    "encoder_lr = 1e-4             # This is used with encoder if 'fine-tunning' is enabled\n",
    "decoder_lr = 4e-4             # LSTM learning rate\n",
    "grad_clip = 5.0               # Clip the gradients at this value\n",
    "alpha_c = 1.0                 # Regularization for attention; implementation from the original paper\n",
    "best_bleu4 = 0.0              # This tracks the BLUE-4 score\n",
    "print_freq = 200    \n",
    "fine_tune_encoder = True     # Do we train the encoder?\n",
    "checkpoint = None             # Path to checkpoint, \"None\" if none\n",
    "torch.cuda.get_device_name(0) # check if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A walk through of what will happen later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the next gourpd of training data from loader\n",
    "imgs, caps, caplens = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 256, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into GPU device\n",
    "imgs = imgs.to(device)\n",
    "caps = caps.to(device)\n",
    "caplens = caplens.to(device)\n",
    "\n",
    "# Pass through CNN encoder\n",
    "imgs = encoder(imgs)   # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "\n",
    "# Pass through RNN decoder\n",
    "scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 26, 9490])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 52])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_sorted.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decode_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequence so that we can calculate the loss later\n",
    "scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "targets = caps_sorted[:, 1:]\n",
    "targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(scores.data, targets.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have the loss to perform back propogate\n",
    "All the rest can be handled by Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2427, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    tain_loader: DataLoader for the training data\n",
    "    encoder: encoder model\n",
    "    decoder: decoder model\n",
    "    criterion: loss function\n",
    "    encoder_optimizer: optimizer for the encoder(if fine-tuning is on)\n",
    "    decoder_optimizer: optimizer for the LSTM\n",
    "    epoch: epoch number\n",
    "    \"\"\"\n",
    "    \n",
    "    decoder.train()    # Training mode\n",
    "    encoder.train()\n",
    "    \n",
    "    # AverageMeter() is imported from utils.py to track the most recent, average, sum, and count of a metric.\n",
    "    batch_time = AverageMeter()   # forward prop + back prop time\n",
    "    data_time = AverageMeter()    # data loading time\n",
    "    losses = AverageMeter()       # loss (per word decoded)\n",
    "    top5accs = AverageMeter()     # top5 accuracy\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Batches\n",
    "    for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "        \n",
    "        # Move data to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "        \n",
    "        # Forward prop.\n",
    "        imgs = encoder(imgs)   # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens) \n",
    "        # scores-(batch_size_t, vocab_size) \n",
    "        # caps_sorted-(batch_size, max_caption_length)\n",
    "        # decode_lengths-[caption_lengths -1]\n",
    "        # alphas, pixel-wise attention, (batch_size, max(decode_lengths), num_pixels)\n",
    "        # sort_ind: this index sort the lengths of captions in descending order\n",
    "        \n",
    "        # Since we decoded staring with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        \n",
    "        # Remove timesteps that we didn't encode at, or are pads\n",
    "        # pack_padded_sentence to fo this trick\n",
    "        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(scores.data, targets.data)\n",
    "        \n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "        \n",
    "        # BackProp.\n",
    "        decoder_optimizer.zero_grad()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "        \n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "            \n",
    "        # Keep track of metrics\n",
    "        top5 = accuracy(scores.data, targets.data, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses,\n",
    "                                                                          top5=top5accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    \"\"\"\n",
    "    val_loader: DataLoader for validation data\n",
    "    encoder: trained encoder model\n",
    "    decoder: trained decoder model\n",
    "    criterion: loss function\n",
    "    \n",
    "    return: BLEU-4 score\n",
    "    \"\"\"\n",
    "    decoder.eval() # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "    start = time.time()\n",
    "    \n",
    "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
    "    hypotheses = list()  # references (predictions)\n",
    "    \n",
    "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
    "    with torch.no_grad():\n",
    "        # Batches\n",
    "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
    "            # move to GPU\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "            \n",
    "            # Forward prop.\n",
    "            if encoder is not None:\n",
    "                imgs = encoder(imgs)\n",
    "            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "            \n",
    "            # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "            # \"caps_sorted\" is the \"caps\" tensor sorted with descending caption_length order. (batch_size, max_caption_length)\n",
    "            targets = caps_sorted[:, 1:]   # this matchs the position of target to predictions\n",
    "            \n",
    "            # Remove timesteps that we didn't decode at, or are pads\n",
    "            # pack_padded_sequence can do this trick\n",
    "            scores_copy = scores.clone()\n",
    "            scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "            targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(scores.data, targets.data)\n",
    "            \n",
    "            # Add doubly stochastic attention regularization\n",
    "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "            \n",
    "            # Keep track of metrics\n",
    "            losses.update(loss.item(), sum(decode_lengths))\n",
    "            top5 = accuracy(scores.data, targets.data, 5)\n",
    "            top5accs.update(top5, sum(decode_lengths))\n",
    "            batch_time.update(time.time() - start)\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\t'\n",
    "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
    "                                                                                loss=losses, top5=top5accs))\n",
    "                \n",
    "            # Store references (true captions), and hypothesis (prediction) for each image\n",
    "            # If for n images, we have n hypotheses, and references a, b, c... for each image, we need\n",
    "            # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b],...], hypotheses = [hyp1, hyp2, ...]\n",
    "            \n",
    "            # References\n",
    "            allcaps = allcaps[sort_ind] # the captions are sorted in the decoder\n",
    "            for j in range(allcaps.shape[0]):\n",
    "                img_caps = allcaps[j].tolist()\n",
    "                img_captions = list(\n",
    "                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}], \n",
    "                        img_caps))   # remove <start> and pads\n",
    "                references.append(img_captions)\n",
    "            \n",
    "            # Hypotheses\n",
    "            _, preds = torch.max(scores_copy, dim=2)\n",
    "            preds = preds.tolist()\n",
    "            temp_preds = list()\n",
    "            for j,p in enumerate(preds):\n",
    "                temp_preds.append(preds[j][:decode_lengths[j]])   # remove pads\n",
    "            preds = temp_preds\n",
    "            hypotheses.extend(preds)\n",
    "            \n",
    "            assert len(references) == len(hypotheses)\n",
    "            \n",
    "        # Calculate BLEU-4 scores\n",
    "        bleu4 = corpus_bleu(references, hypotheses)\n",
    "        \n",
    "        print(\n",
    "            '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n",
    "                loss=losses,\n",
    "                top5=top5accs,\n",
    "                bleu=bleu4))\n",
    "\n",
    "    return bleu4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load our word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of the vocabulary is :9490\n"
     ]
    }
   ],
   "source": [
    "global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "print(f\"The total size of the vocabulary is :{len(word_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize / load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint is None:\n",
    "    decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                                   embed_dim=emb_dim,\n",
    "                                   decoder_dim=decoder_dim,\n",
    "                                   vocab_size=len(word_map),\n",
    "                                   dropout=dropout\n",
    "                                  )\n",
    "    decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                             lr=decoder_lr)\n",
    "    encoder = Encoder()\n",
    "    encoder.fine_tune(fine_tune_encoder)\n",
    "    encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                             lr=encoder_lr) if fine_tune_encoder else None\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "    best_bleu4 = checkpoint['bleu-4']\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "    if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "        encoder.fine_tune(fine_tune_encoder)\n",
    "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                                 lr=encoder_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "    batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/17702]\tBatch Time 6.600 (6.600)\tData Load Time 0.876 (0.876)\tLoss 10.0792 (10.0792)\tTop-5 Accuracy 0.000 (0.000)\n",
      "Epoch: [0][200/17702]\tBatch Time 1.141 (1.301)\tData Load Time 0.500 (0.553)\tLoss 5.4749 (6.1580)\tTop-5 Accuracy 44.180 (38.731)\n",
      "Epoch: [0][400/17702]\tBatch Time 1.156 (1.275)\tData Load Time 0.469 (0.540)\tLoss 4.8203 (5.6753)\tTop-5 Accuracy 54.717 (44.448)\n",
      "Epoch: [0][600/17702]\tBatch Time 1.172 (1.260)\tData Load Time 0.453 (0.531)\tLoss 4.4033 (5.3984)\tTop-5 Accuracy 59.524 (47.907)\n",
      "Epoch: [0][800/17702]\tBatch Time 1.172 (1.246)\tData Load Time 0.484 (0.519)\tLoss 4.6233 (5.2172)\tTop-5 Accuracy 57.143 (50.215)\n",
      "Epoch: [0][1000/17702]\tBatch Time 1.141 (1.228)\tData Load Time 0.422 (0.505)\tLoss 4.2600 (5.0831)\tTop-5 Accuracy 65.181 (51.967)\n",
      "Epoch: [0][1200/17702]\tBatch Time 1.094 (1.214)\tData Load Time 0.437 (0.493)\tLoss 4.5515 (4.9761)\tTop-5 Accuracy 58.575 (53.310)\n",
      "Epoch: [0][1400/17702]\tBatch Time 1.031 (1.203)\tData Load Time 0.359 (0.483)\tLoss 4.4792 (4.8921)\tTop-5 Accuracy 63.243 (54.375)\n",
      "Epoch: [0][1600/17702]\tBatch Time 1.094 (1.194)\tData Load Time 0.375 (0.474)\tLoss 4.3795 (4.8203)\tTop-5 Accuracy 61.702 (55.307)\n",
      "Epoch: [0][1800/17702]\tBatch Time 0.969 (1.184)\tData Load Time 0.312 (0.465)\tLoss 3.8144 (4.7593)\tTop-5 Accuracy 66.857 (56.074)\n",
      "Epoch: [0][2000/17702]\tBatch Time 1.172 (1.183)\tData Load Time 0.406 (0.463)\tLoss 4.2668 (4.7047)\tTop-5 Accuracy 61.069 (56.769)\n",
      "Epoch: [0][2200/17702]\tBatch Time 1.141 (1.180)\tData Load Time 0.375 (0.459)\tLoss 3.7653 (4.6578)\tTop-5 Accuracy 69.780 (57.375)\n",
      "Epoch: [0][2400/17702]\tBatch Time 0.937 (1.172)\tData Load Time 0.281 (0.452)\tLoss 4.0472 (4.6123)\tTop-5 Accuracy 63.768 (57.950)\n",
      "Epoch: [0][2600/17702]\tBatch Time 1.125 (1.165)\tData Load Time 0.422 (0.445)\tLoss 3.9345 (4.5710)\tTop-5 Accuracy 62.000 (58.473)\n",
      "Epoch: [0][2800/17702]\tBatch Time 1.062 (1.158)\tData Load Time 0.422 (0.439)\tLoss 4.4105 (4.5365)\tTop-5 Accuracy 58.757 (58.911)\n",
      "Epoch: [0][3000/17702]\tBatch Time 1.141 (1.154)\tData Load Time 0.484 (0.434)\tLoss 4.0819 (4.5014)\tTop-5 Accuracy 63.926 (59.371)\n",
      "Epoch: [0][3200/17702]\tBatch Time 1.047 (1.149)\tData Load Time 0.391 (0.429)\tLoss 3.7669 (4.4685)\tTop-5 Accuracy 69.169 (59.800)\n",
      "Epoch: [0][3400/17702]\tBatch Time 1.172 (1.145)\tData Load Time 0.453 (0.426)\tLoss 3.7624 (4.4394)\tTop-5 Accuracy 67.352 (60.169)\n",
      "Epoch: [0][3600/17702]\tBatch Time 1.187 (1.142)\tData Load Time 0.422 (0.423)\tLoss 4.0642 (4.4124)\tTop-5 Accuracy 68.120 (60.518)\n",
      "Epoch: [0][3800/17702]\tBatch Time 1.078 (1.139)\tData Load Time 0.359 (0.419)\tLoss 3.9481 (4.3872)\tTop-5 Accuracy 66.313 (60.844)\n",
      "Epoch: [0][4000/17702]\tBatch Time 1.031 (1.136)\tData Load Time 0.391 (0.417)\tLoss 3.8732 (4.3620)\tTop-5 Accuracy 65.374 (61.161)\n",
      "Epoch: [0][4200/17702]\tBatch Time 1.078 (1.133)\tData Load Time 0.359 (0.413)\tLoss 4.1104 (4.3401)\tTop-5 Accuracy 63.014 (61.449)\n",
      "Epoch: [0][4400/17702]\tBatch Time 1.073 (1.130)\tData Load Time 0.375 (0.411)\tLoss 3.7918 (4.3185)\tTop-5 Accuracy 68.067 (61.733)\n",
      "Epoch: [0][4600/17702]\tBatch Time 1.125 (1.127)\tData Load Time 0.328 (0.408)\tLoss 3.5743 (4.2993)\tTop-5 Accuracy 71.930 (61.984)\n",
      "Epoch: [0][4800/17702]\tBatch Time 1.062 (1.125)\tData Load Time 0.375 (0.406)\tLoss 3.8716 (4.2811)\tTop-5 Accuracy 68.421 (62.218)\n",
      "Epoch: [0][5000/17702]\tBatch Time 1.094 (1.122)\tData Load Time 0.344 (0.404)\tLoss 3.6398 (4.2633)\tTop-5 Accuracy 70.619 (62.438)\n",
      "Epoch: [0][5200/17702]\tBatch Time 1.109 (1.121)\tData Load Time 0.391 (0.402)\tLoss 3.7646 (4.2463)\tTop-5 Accuracy 66.474 (62.659)\n",
      "Epoch: [0][5400/17702]\tBatch Time 1.016 (1.120)\tData Load Time 0.297 (0.402)\tLoss 3.6867 (4.2296)\tTop-5 Accuracy 70.649 (62.877)\n",
      "Epoch: [0][5600/17702]\tBatch Time 1.062 (1.118)\tData Load Time 0.344 (0.400)\tLoss 3.4388 (4.2148)\tTop-5 Accuracy 74.797 (63.068)\n",
      "Epoch: [0][5800/17702]\tBatch Time 1.094 (1.117)\tData Load Time 0.344 (0.399)\tLoss 3.7765 (4.1992)\tTop-5 Accuracy 68.280 (63.268)\n",
      "Epoch: [0][6000/17702]\tBatch Time 1.078 (1.115)\tData Load Time 0.344 (0.397)\tLoss 4.0631 (4.1846)\tTop-5 Accuracy 65.796 (63.456)\n",
      "Epoch: [0][6200/17702]\tBatch Time 1.000 (1.113)\tData Load Time 0.328 (0.396)\tLoss 3.5979 (4.1710)\tTop-5 Accuracy 68.732 (63.626)\n",
      "Epoch: [0][6400/17702]\tBatch Time 1.062 (1.112)\tData Load Time 0.375 (0.396)\tLoss 3.7931 (4.1581)\tTop-5 Accuracy 68.901 (63.793)\n",
      "Epoch: [0][6600/17702]\tBatch Time 1.078 (1.111)\tData Load Time 0.344 (0.394)\tLoss 3.4774 (4.1456)\tTop-5 Accuracy 71.351 (63.952)\n",
      "Epoch: [0][6800/17702]\tBatch Time 1.078 (1.110)\tData Load Time 0.391 (0.393)\tLoss 3.6626 (4.1337)\tTop-5 Accuracy 70.893 (64.107)\n",
      "Epoch: [0][7000/17702]\tBatch Time 1.047 (1.109)\tData Load Time 0.328 (0.392)\tLoss 3.6225 (4.1212)\tTop-5 Accuracy 69.663 (64.267)\n",
      "Epoch: [0][7200/17702]\tBatch Time 0.984 (1.108)\tData Load Time 0.313 (0.391)\tLoss 3.8176 (4.1100)\tTop-5 Accuracy 67.374 (64.408)\n",
      "Epoch: [0][7400/17702]\tBatch Time 1.031 (1.107)\tData Load Time 0.312 (0.390)\tLoss 3.7234 (4.0986)\tTop-5 Accuracy 70.083 (64.553)\n",
      "Epoch: [0][7600/17702]\tBatch Time 1.062 (1.106)\tData Load Time 0.359 (0.389)\tLoss 3.7758 (4.0878)\tTop-5 Accuracy 68.563 (64.694)\n",
      "Epoch: [0][7800/17702]\tBatch Time 1.062 (1.105)\tData Load Time 0.359 (0.388)\tLoss 3.9913 (4.0777)\tTop-5 Accuracy 64.624 (64.823)\n",
      "Epoch: [0][8000/17702]\tBatch Time 1.094 (1.104)\tData Load Time 0.406 (0.388)\tLoss 3.8713 (4.0679)\tTop-5 Accuracy 69.653 (64.952)\n",
      "Epoch: [0][8200/17702]\tBatch Time 1.062 (1.103)\tData Load Time 0.375 (0.387)\tLoss 3.6946 (4.0587)\tTop-5 Accuracy 68.919 (65.067)\n",
      "Epoch: [0][8400/17702]\tBatch Time 1.156 (1.103)\tData Load Time 0.406 (0.387)\tLoss 4.0043 (4.0494)\tTop-5 Accuracy 67.021 (65.187)\n",
      "Epoch: [0][8600/17702]\tBatch Time 1.047 (1.102)\tData Load Time 0.359 (0.386)\tLoss 3.7007 (4.0401)\tTop-5 Accuracy 71.802 (65.307)\n",
      "Epoch: [0][8800/17702]\tBatch Time 1.094 (1.102)\tData Load Time 0.391 (0.386)\tLoss 3.1023 (4.0311)\tTop-5 Accuracy 77.562 (65.423)\n",
      "Epoch: [0][9000/17702]\tBatch Time 1.031 (1.101)\tData Load Time 0.281 (0.385)\tLoss 3.6316 (4.0226)\tTop-5 Accuracy 73.842 (65.535)\n",
      "Epoch: [0][9200/17702]\tBatch Time 1.062 (1.101)\tData Load Time 0.375 (0.384)\tLoss 3.4996 (4.0143)\tTop-5 Accuracy 73.926 (65.643)\n",
      "Epoch: [0][9400/17702]\tBatch Time 1.062 (1.100)\tData Load Time 0.375 (0.384)\tLoss 3.3065 (4.0066)\tTop-5 Accuracy 74.855 (65.745)\n",
      "Epoch: [0][9600/17702]\tBatch Time 1.000 (1.099)\tData Load Time 0.328 (0.383)\tLoss 3.8088 (3.9987)\tTop-5 Accuracy 66.116 (65.846)\n",
      "Epoch: [0][9800/17702]\tBatch Time 1.000 (1.099)\tData Load Time 0.297 (0.383)\tLoss 3.8223 (3.9914)\tTop-5 Accuracy 71.117 (65.939)\n",
      "Epoch: [0][10000/17702]\tBatch Time 1.109 (1.098)\tData Load Time 0.359 (0.382)\tLoss 3.7990 (3.9835)\tTop-5 Accuracy 70.792 (66.043)\n",
      "Epoch: [0][10200/17702]\tBatch Time 1.016 (1.098)\tData Load Time 0.328 (0.382)\tLoss 3.5647 (3.9761)\tTop-5 Accuracy 73.003 (66.140)\n",
      "Epoch: [0][10400/17702]\tBatch Time 0.937 (1.097)\tData Load Time 0.297 (0.381)\tLoss 3.6311 (3.9690)\tTop-5 Accuracy 69.972 (66.232)\n",
      "Epoch: [0][10600/17702]\tBatch Time 1.031 (1.097)\tData Load Time 0.328 (0.381)\tLoss 3.6835 (3.9619)\tTop-5 Accuracy 68.733 (66.322)\n",
      "Epoch: [0][10800/17702]\tBatch Time 1.047 (1.096)\tData Load Time 0.312 (0.380)\tLoss 3.4472 (3.9551)\tTop-5 Accuracy 72.606 (66.413)\n",
      "Epoch: [0][11000/17702]\tBatch Time 0.984 (1.096)\tData Load Time 0.328 (0.380)\tLoss 3.3328 (3.9484)\tTop-5 Accuracy 73.077 (66.500)\n",
      "Epoch: [0][11200/17702]\tBatch Time 1.281 (1.098)\tData Load Time 0.625 (0.382)\tLoss 3.5570 (3.9417)\tTop-5 Accuracy 71.388 (66.589)\n",
      "Epoch: [0][11400/17702]\tBatch Time 1.187 (1.104)\tData Load Time 0.453 (0.388)\tLoss 3.6301 (3.9353)\tTop-5 Accuracy 70.857 (66.672)\n",
      "Epoch: [0][11600/17702]\tBatch Time 1.141 (1.104)\tData Load Time 0.422 (0.387)\tLoss 3.5680 (3.9289)\tTop-5 Accuracy 70.845 (66.756)\n",
      "Epoch: [0][11800/17702]\tBatch Time 1.016 (1.103)\tData Load Time 0.359 (0.387)\tLoss 3.5690 (3.9227)\tTop-5 Accuracy 71.237 (66.833)\n",
      "Epoch: [0][12000/17702]\tBatch Time 1.656 (1.104)\tData Load Time 0.937 (0.387)\tLoss 3.4240 (3.9169)\tTop-5 Accuracy 72.753 (66.905)\n",
      "Epoch: [0][12200/17702]\tBatch Time 1.048 (1.105)\tData Load Time 0.392 (0.388)\tLoss 3.8062 (3.9115)\tTop-5 Accuracy 68.347 (66.977)\n",
      "Epoch: [0][12400/17702]\tBatch Time 1.144 (1.104)\tData Load Time 0.377 (0.388)\tLoss 3.6383 (3.9058)\tTop-5 Accuracy 67.632 (67.048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][12600/17702]\tBatch Time 1.031 (1.104)\tData Load Time 0.375 (0.387)\tLoss 3.5631 (3.9005)\tTop-5 Accuracy 68.508 (67.119)\n",
      "Epoch: [0][12800/17702]\tBatch Time 1.047 (1.104)\tData Load Time 0.359 (0.387)\tLoss 3.4716 (3.8947)\tTop-5 Accuracy 71.467 (67.196)\n",
      "Epoch: [0][13000/17702]\tBatch Time 1.000 (1.103)\tData Load Time 0.344 (0.386)\tLoss 3.8411 (3.8893)\tTop-5 Accuracy 70.195 (67.270)\n",
      "Epoch: [0][13200/17702]\tBatch Time 1.031 (1.103)\tData Load Time 0.344 (0.386)\tLoss 3.3406 (3.8842)\tTop-5 Accuracy 72.581 (67.336)\n",
      "Epoch: [0][13400/17702]\tBatch Time 1.031 (1.102)\tData Load Time 0.375 (0.385)\tLoss 3.1991 (3.8793)\tTop-5 Accuracy 76.099 (67.398)\n",
      "Epoch: [0][13600/17702]\tBatch Time 1.125 (1.102)\tData Load Time 0.422 (0.385)\tLoss 3.5131 (3.8741)\tTop-5 Accuracy 72.441 (67.465)\n",
      "Epoch: [0][13800/17702]\tBatch Time 1.000 (1.102)\tData Load Time 0.359 (0.385)\tLoss 3.6828 (3.8692)\tTop-5 Accuracy 69.859 (67.530)\n",
      "Epoch: [0][14000/17702]\tBatch Time 1.062 (1.101)\tData Load Time 0.406 (0.385)\tLoss 3.3423 (3.8644)\tTop-5 Accuracy 73.504 (67.596)\n",
      "Epoch: [0][14200/17702]\tBatch Time 1.109 (1.101)\tData Load Time 0.375 (0.384)\tLoss 3.6048 (3.8595)\tTop-5 Accuracy 68.805 (67.661)\n",
      "Epoch: [0][14400/17702]\tBatch Time 1.062 (1.101)\tData Load Time 0.312 (0.384)\tLoss 3.9330 (3.8546)\tTop-5 Accuracy 69.169 (67.728)\n",
      "Epoch: [0][14600/17702]\tBatch Time 1.000 (1.100)\tData Load Time 0.328 (0.384)\tLoss 3.5539 (3.8497)\tTop-5 Accuracy 72.253 (67.792)\n",
      "Epoch: [0][14800/17702]\tBatch Time 1.031 (1.100)\tData Load Time 0.281 (0.383)\tLoss 3.5057 (3.8448)\tTop-5 Accuracy 73.003 (67.856)\n",
      "Epoch: [0][15000/17702]\tBatch Time 1.094 (1.100)\tData Load Time 0.422 (0.383)\tLoss 3.2265 (3.8404)\tTop-5 Accuracy 76.503 (67.915)\n",
      "Epoch: [0][15200/17702]\tBatch Time 1.031 (1.099)\tData Load Time 0.344 (0.382)\tLoss 3.7854 (3.8361)\tTop-5 Accuracy 71.257 (67.972)\n",
      "Epoch: [0][15400/17702]\tBatch Time 0.969 (1.099)\tData Load Time 0.328 (0.382)\tLoss 3.6139 (3.8318)\tTop-5 Accuracy 68.286 (68.029)\n",
      "Epoch: [0][15600/17702]\tBatch Time 1.172 (1.098)\tData Load Time 0.406 (0.382)\tLoss 3.5927 (3.8277)\tTop-5 Accuracy 72.251 (68.084)\n",
      "Epoch: [0][15800/17702]\tBatch Time 1.281 (1.098)\tData Load Time 0.437 (0.382)\tLoss 3.6978 (3.8235)\tTop-5 Accuracy 69.315 (68.140)\n",
      "Epoch: [0][16000/17702]\tBatch Time 1.062 (1.098)\tData Load Time 0.359 (0.381)\tLoss 3.4551 (3.8195)\tTop-5 Accuracy 71.968 (68.192)\n",
      "Epoch: [0][16200/17702]\tBatch Time 1.047 (1.097)\tData Load Time 0.375 (0.381)\tLoss 3.4613 (3.8154)\tTop-5 Accuracy 71.892 (68.245)\n",
      "Epoch: [0][16400/17702]\tBatch Time 1.000 (1.097)\tData Load Time 0.344 (0.381)\tLoss 3.3863 (3.8116)\tTop-5 Accuracy 71.676 (68.295)\n",
      "Epoch: [0][16600/17702]\tBatch Time 1.047 (1.097)\tData Load Time 0.359 (0.380)\tLoss 3.9357 (3.8077)\tTop-5 Accuracy 67.560 (68.346)\n",
      "Epoch: [0][16800/17702]\tBatch Time 1.125 (1.097)\tData Load Time 0.344 (0.380)\tLoss 3.6352 (3.8040)\tTop-5 Accuracy 70.466 (68.394)\n",
      "Epoch: [0][17000/17702]\tBatch Time 1.078 (1.097)\tData Load Time 0.359 (0.380)\tLoss 3.2300 (3.8002)\tTop-5 Accuracy 78.610 (68.445)\n",
      "Epoch: [0][17200/17702]\tBatch Time 0.969 (1.096)\tData Load Time 0.266 (0.380)\tLoss 3.4394 (3.7962)\tTop-5 Accuracy 74.934 (68.495)\n",
      "Epoch: [0][17400/17702]\tBatch Time 1.047 (1.096)\tData Load Time 0.375 (0.379)\tLoss 3.4059 (3.7925)\tTop-5 Accuracy 73.611 (68.547)\n",
      "Epoch: [0][17600/17702]\tBatch Time 1.016 (1.096)\tData Load Time 0.328 (0.379)\tLoss 3.4128 (3.7889)\tTop-5 Accuracy 73.295 (68.595)\n",
      "Validation: [0/782]\tBatch Time 0.734 (0.734)\tLoss 3.4870 (3.4870)\tTop-5 Accuracy 73.171 (73.171)\t\n",
      "Validation: [200/782]\tBatch Time 0.453 (0.536)\tLoss 3.3458 (3.3637)\tTop-5 Accuracy 74.444 (73.916)\t\n",
      "Validation: [400/782]\tBatch Time 0.297 (0.447)\tLoss 3.3414 (3.3631)\tTop-5 Accuracy 74.366 (73.940)\t\n",
      "Validation: [600/782]\tBatch Time 0.266 (0.401)\tLoss 3.3885 (3.3675)\tTop-5 Accuracy 73.757 (73.964)\t\n",
      "\n",
      " * LOSS - 3.369, TOP-5 ACCURACY - 73.928, BLEU-4 - 0.2091813808732269\n",
      "\n",
      "Epoch: [1][0/17702]\tBatch Time 2.125 (2.125)\tData Load Time 1.016 (1.016)\tLoss 3.3664 (3.3664)\tTop-5 Accuracy 75.718 (75.718)\n",
      "Epoch: [1][200/17702]\tBatch Time 0.984 (1.124)\tData Load Time 0.312 (0.407)\tLoss 3.6028 (3.4082)\tTop-5 Accuracy 68.767 (73.408)\n",
      "Epoch: [1][400/17702]\tBatch Time 1.047 (1.109)\tData Load Time 0.375 (0.396)\tLoss 3.1874 (3.4016)\tTop-5 Accuracy 74.722 (73.510)\n",
      "Epoch: [1][600/17702]\tBatch Time 1.187 (1.108)\tData Load Time 0.406 (0.396)\tLoss 3.1830 (3.4030)\tTop-5 Accuracy 74.674 (73.523)\n",
      "Epoch: [1][800/17702]\tBatch Time 1.141 (1.109)\tData Load Time 0.391 (0.394)\tLoss 3.1531 (3.4052)\tTop-5 Accuracy 76.944 (73.522)\n",
      "Epoch: [1][1000/17702]\tBatch Time 0.969 (1.122)\tData Load Time 0.344 (0.406)\tLoss 3.1805 (3.4056)\tTop-5 Accuracy 75.211 (73.512)\n",
      "Epoch: [1][1200/17702]\tBatch Time 1.172 (1.118)\tData Load Time 0.391 (0.403)\tLoss 3.1161 (3.4033)\tTop-5 Accuracy 79.699 (73.513)\n",
      "Epoch: [1][1400/17702]\tBatch Time 1.156 (1.116)\tData Load Time 0.516 (0.403)\tLoss 3.4109 (3.4020)\tTop-5 Accuracy 73.504 (73.514)\n",
      "Epoch: [1][1600/17702]\tBatch Time 1.031 (1.115)\tData Load Time 0.359 (0.402)\tLoss 3.3457 (3.4013)\tTop-5 Accuracy 73.984 (73.546)\n",
      "Epoch: [1][1800/17702]\tBatch Time 1.000 (1.114)\tData Load Time 0.297 (0.400)\tLoss 3.4361 (3.3996)\tTop-5 Accuracy 73.298 (73.580)\n",
      "Epoch: [1][2000/17702]\tBatch Time 1.156 (1.111)\tData Load Time 0.453 (0.397)\tLoss 3.5049 (3.4019)\tTop-5 Accuracy 71.429 (73.559)\n",
      "Epoch: [1][2200/17702]\tBatch Time 1.062 (1.107)\tData Load Time 0.359 (0.394)\tLoss 3.2757 (3.3993)\tTop-5 Accuracy 75.266 (73.602)\n",
      "Epoch: [1][2400/17702]\tBatch Time 1.172 (1.104)\tData Load Time 0.406 (0.390)\tLoss 3.4035 (3.3983)\tTop-5 Accuracy 74.485 (73.614)\n",
      "Epoch: [1][2600/17702]\tBatch Time 1.109 (1.103)\tData Load Time 0.328 (0.388)\tLoss 3.5107 (3.3974)\tTop-5 Accuracy 72.312 (73.627)\n",
      "Epoch: [1][2800/17702]\tBatch Time 1.031 (1.101)\tData Load Time 0.344 (0.385)\tLoss 3.3273 (3.3954)\tTop-5 Accuracy 74.631 (73.652)\n",
      "Epoch: [1][3000/17702]\tBatch Time 1.078 (1.100)\tData Load Time 0.359 (0.384)\tLoss 3.5674 (3.3933)\tTop-5 Accuracy 68.158 (73.674)\n",
      "Epoch: [1][3200/17702]\tBatch Time 0.984 (1.097)\tData Load Time 0.281 (0.382)\tLoss 3.4094 (3.3930)\tTop-5 Accuracy 74.935 (73.681)\n",
      "Epoch: [1][3400/17702]\tBatch Time 0.984 (1.095)\tData Load Time 0.328 (0.381)\tLoss 3.4294 (3.3927)\tTop-5 Accuracy 75.281 (73.691)\n",
      "Epoch: [1][3600/17702]\tBatch Time 1.094 (1.094)\tData Load Time 0.344 (0.379)\tLoss 3.1930 (3.3919)\tTop-5 Accuracy 75.591 (73.707)\n",
      "Epoch: [1][3800/17702]\tBatch Time 1.062 (1.092)\tData Load Time 0.344 (0.378)\tLoss 3.3759 (3.3908)\tTop-5 Accuracy 74.797 (73.722)\n",
      "Epoch: [1][4000/17702]\tBatch Time 1.047 (1.092)\tData Load Time 0.266 (0.377)\tLoss 3.3314 (3.3889)\tTop-5 Accuracy 75.676 (73.754)\n",
      "Epoch: [1][4200/17702]\tBatch Time 0.984 (1.091)\tData Load Time 0.359 (0.376)\tLoss 3.1077 (3.3889)\tTop-5 Accuracy 79.023 (73.759)\n",
      "Epoch: [1][4400/17702]\tBatch Time 1.031 (1.090)\tData Load Time 0.375 (0.375)\tLoss 3.4894 (3.3891)\tTop-5 Accuracy 72.752 (73.750)\n",
      "Epoch: [1][4600/17702]\tBatch Time 0.937 (1.089)\tData Load Time 0.297 (0.374)\tLoss 3.2272 (3.3889)\tTop-5 Accuracy 79.661 (73.752)\n",
      "Epoch: [1][4800/17702]\tBatch Time 0.922 (1.089)\tData Load Time 0.281 (0.374)\tLoss 3.4366 (3.3886)\tTop-5 Accuracy 75.135 (73.765)\n",
      "Epoch: [1][5000/17702]\tBatch Time 1.000 (1.088)\tData Load Time 0.375 (0.373)\tLoss 3.0224 (3.3875)\tTop-5 Accuracy 76.744 (73.778)\n",
      "Epoch: [1][5200/17702]\tBatch Time 1.000 (1.087)\tData Load Time 0.328 (0.373)\tLoss 3.0914 (3.3865)\tTop-5 Accuracy 78.448 (73.797)\n",
      "Epoch: [1][5400/17702]\tBatch Time 1.047 (1.087)\tData Load Time 0.359 (0.372)\tLoss 3.1964 (3.3863)\tTop-5 Accuracy 76.694 (73.793)\n",
      "Epoch: [1][5600/17702]\tBatch Time 1.094 (1.086)\tData Load Time 0.344 (0.371)\tLoss 3.5226 (3.3859)\tTop-5 Accuracy 72.362 (73.796)\n",
      "Epoch: [1][5800/17702]\tBatch Time 1.016 (1.086)\tData Load Time 0.281 (0.371)\tLoss 3.4181 (3.3850)\tTop-5 Accuracy 75.815 (73.813)\n",
      "Epoch: [1][6000/17702]\tBatch Time 1.109 (1.085)\tData Load Time 0.359 (0.371)\tLoss 3.5455 (3.3846)\tTop-5 Accuracy 72.000 (73.822)\n",
      "Epoch: [1][6200/17702]\tBatch Time 1.000 (1.085)\tData Load Time 0.312 (0.370)\tLoss 3.3248 (3.3835)\tTop-5 Accuracy 74.531 (73.834)\n",
      "Epoch: [1][6400/17702]\tBatch Time 1.016 (1.084)\tData Load Time 0.359 (0.370)\tLoss 3.4465 (3.3827)\tTop-5 Accuracy 73.596 (73.850)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6600/17702]\tBatch Time 1.047 (1.084)\tData Load Time 0.359 (0.370)\tLoss 3.3746 (3.3816)\tTop-5 Accuracy 75.562 (73.872)\n",
      "Epoch: [1][6800/17702]\tBatch Time 1.172 (1.084)\tData Load Time 0.359 (0.369)\tLoss 3.4370 (3.3806)\tTop-5 Accuracy 74.607 (73.882)\n",
      "Epoch: [1][7000/17702]\tBatch Time 1.141 (1.083)\tData Load Time 0.422 (0.369)\tLoss 3.4291 (3.3804)\tTop-5 Accuracy 72.299 (73.889)\n",
      "Epoch: [1][7200/17702]\tBatch Time 0.984 (1.083)\tData Load Time 0.328 (0.368)\tLoss 3.6055 (3.3795)\tTop-5 Accuracy 69.359 (73.904)\n",
      "Epoch: [1][7400/17702]\tBatch Time 1.000 (1.083)\tData Load Time 0.359 (0.369)\tLoss 3.3419 (3.3792)\tTop-5 Accuracy 73.926 (73.910)\n",
      "Epoch: [1][7600/17702]\tBatch Time 0.922 (1.083)\tData Load Time 0.266 (0.368)\tLoss 3.1014 (3.3783)\tTop-5 Accuracy 79.037 (73.923)\n",
      "Epoch: [1][7800/17702]\tBatch Time 1.125 (1.082)\tData Load Time 0.281 (0.368)\tLoss 3.3390 (3.3774)\tTop-5 Accuracy 74.615 (73.935)\n",
      "Epoch: [1][8000/17702]\tBatch Time 0.969 (1.082)\tData Load Time 0.312 (0.368)\tLoss 3.1932 (3.3774)\tTop-5 Accuracy 73.938 (73.940)\n",
      "Epoch: [1][8200/17702]\tBatch Time 1.000 (1.082)\tData Load Time 0.312 (0.367)\tLoss 3.0549 (3.3770)\tTop-5 Accuracy 78.649 (73.947)\n",
      "Epoch: [1][8400/17702]\tBatch Time 1.141 (1.081)\tData Load Time 0.422 (0.367)\tLoss 2.7345 (3.3765)\tTop-5 Accuracy 82.979 (73.960)\n",
      "Epoch: [1][8600/17702]\tBatch Time 1.047 (1.081)\tData Load Time 0.375 (0.367)\tLoss 3.4959 (3.3758)\tTop-5 Accuracy 74.366 (73.972)\n",
      "Epoch: [1][8800/17702]\tBatch Time 1.172 (1.081)\tData Load Time 0.375 (0.367)\tLoss 3.3138 (3.3747)\tTop-5 Accuracy 73.684 (73.987)\n",
      "Epoch: [1][9000/17702]\tBatch Time 1.000 (1.081)\tData Load Time 0.328 (0.367)\tLoss 3.3294 (3.3737)\tTop-5 Accuracy 74.728 (74.002)\n",
      "Epoch: [1][9200/17702]\tBatch Time 1.141 (1.081)\tData Load Time 0.406 (0.366)\tLoss 3.4668 (3.3728)\tTop-5 Accuracy 73.204 (74.015)\n",
      "Epoch: [1][9400/17702]\tBatch Time 1.109 (1.081)\tData Load Time 0.406 (0.366)\tLoss 3.0700 (3.3720)\tTop-5 Accuracy 79.890 (74.030)\n",
      "Epoch: [1][9600/17702]\tBatch Time 1.156 (1.080)\tData Load Time 0.375 (0.366)\tLoss 3.1382 (3.3717)\tTop-5 Accuracy 76.437 (74.039)\n",
      "Epoch: [1][9800/17702]\tBatch Time 1.031 (1.080)\tData Load Time 0.359 (0.366)\tLoss 3.6164 (3.3708)\tTop-5 Accuracy 69.189 (74.055)\n",
      "Epoch: [1][10000/17702]\tBatch Time 1.219 (1.080)\tData Load Time 0.406 (0.366)\tLoss 3.1435 (3.3701)\tTop-5 Accuracy 77.953 (74.064)\n",
      "Epoch: [1][10200/17702]\tBatch Time 0.953 (1.080)\tData Load Time 0.297 (0.366)\tLoss 3.3878 (3.3693)\tTop-5 Accuracy 72.922 (74.075)\n",
      "Epoch: [1][10400/17702]\tBatch Time 1.125 (1.080)\tData Load Time 0.422 (0.366)\tLoss 3.5936 (3.3687)\tTop-5 Accuracy 70.330 (74.085)\n",
      "Epoch: [1][10600/17702]\tBatch Time 1.047 (1.080)\tData Load Time 0.328 (0.366)\tLoss 3.5055 (3.3680)\tTop-5 Accuracy 72.269 (74.093)\n",
      "Epoch: [1][10800/17702]\tBatch Time 1.047 (1.080)\tData Load Time 0.344 (0.365)\tLoss 3.4492 (3.3673)\tTop-5 Accuracy 71.547 (74.103)\n",
      "Epoch: [1][11000/17702]\tBatch Time 0.984 (1.080)\tData Load Time 0.297 (0.365)\tLoss 3.4134 (3.3664)\tTop-5 Accuracy 73.770 (74.117)\n",
      "Epoch: [1][11200/17702]\tBatch Time 1.094 (1.079)\tData Load Time 0.328 (0.365)\tLoss 3.0883 (3.3658)\tTop-5 Accuracy 77.836 (74.128)\n",
      "Epoch: [1][11400/17702]\tBatch Time 1.016 (1.079)\tData Load Time 0.344 (0.365)\tLoss 3.3965 (3.3654)\tTop-5 Accuracy 75.000 (74.134)\n",
      "Epoch: [1][11600/17702]\tBatch Time 1.062 (1.079)\tData Load Time 0.328 (0.365)\tLoss 3.1476 (3.3648)\tTop-5 Accuracy 80.000 (74.140)\n",
      "Epoch: [1][11800/17702]\tBatch Time 1.000 (1.080)\tData Load Time 0.297 (0.365)\tLoss 3.2148 (3.3643)\tTop-5 Accuracy 77.384 (74.148)\n",
      "Epoch: [1][12000/17702]\tBatch Time 0.984 (1.079)\tData Load Time 0.312 (0.365)\tLoss 3.4944 (3.3637)\tTop-5 Accuracy 73.088 (74.155)\n",
      "Epoch: [1][12200/17702]\tBatch Time 1.203 (1.079)\tData Load Time 0.422 (0.365)\tLoss 3.1676 (3.3631)\tTop-5 Accuracy 74.550 (74.164)\n",
      "Epoch: [1][12400/17702]\tBatch Time 1.078 (1.080)\tData Load Time 0.312 (0.365)\tLoss 3.2037 (3.3628)\tTop-5 Accuracy 75.260 (74.168)\n",
      "Epoch: [1][12600/17702]\tBatch Time 0.984 (1.080)\tData Load Time 0.328 (0.364)\tLoss 3.4003 (3.3624)\tTop-5 Accuracy 76.571 (74.175)\n",
      "Epoch: [1][12800/17702]\tBatch Time 1.062 (1.080)\tData Load Time 0.375 (0.364)\tLoss 3.7065 (3.3622)\tTop-5 Accuracy 67.330 (74.181)\n",
      "Epoch: [1][13000/17702]\tBatch Time 1.172 (1.079)\tData Load Time 0.406 (0.364)\tLoss 3.2630 (3.3617)\tTop-5 Accuracy 77.836 (74.188)\n",
      "Epoch: [1][13200/17702]\tBatch Time 1.156 (1.079)\tData Load Time 0.453 (0.364)\tLoss 2.9551 (3.3612)\tTop-5 Accuracy 79.076 (74.195)\n",
      "Epoch: [1][13400/17702]\tBatch Time 1.062 (1.079)\tData Load Time 0.312 (0.364)\tLoss 3.2607 (3.3608)\tTop-5 Accuracy 74.138 (74.202)\n",
      "Epoch: [1][13600/17702]\tBatch Time 1.016 (1.079)\tData Load Time 0.344 (0.364)\tLoss 3.0406 (3.3601)\tTop-5 Accuracy 79.009 (74.211)\n",
      "Epoch: [1][13800/17702]\tBatch Time 1.281 (1.079)\tData Load Time 0.359 (0.364)\tLoss 3.5232 (3.3595)\tTop-5 Accuracy 72.460 (74.221)\n",
      "Epoch: [1][14000/17702]\tBatch Time 1.016 (1.079)\tData Load Time 0.297 (0.364)\tLoss 3.2834 (3.3593)\tTop-5 Accuracy 74.194 (74.226)\n",
      "Epoch: [1][14200/17702]\tBatch Time 1.125 (1.079)\tData Load Time 0.328 (0.364)\tLoss 3.4979 (3.3587)\tTop-5 Accuracy 71.100 (74.234)\n",
      "Epoch: [1][14400/17702]\tBatch Time 1.109 (1.079)\tData Load Time 0.375 (0.364)\tLoss 3.2611 (3.3579)\tTop-5 Accuracy 77.322 (74.247)\n",
      "Epoch: [1][14600/17702]\tBatch Time 1.141 (1.079)\tData Load Time 0.453 (0.364)\tLoss 3.0100 (3.3575)\tTop-5 Accuracy 78.611 (74.252)\n",
      "Epoch: [1][14800/17702]\tBatch Time 1.141 (1.078)\tData Load Time 0.422 (0.363)\tLoss 3.3136 (3.3570)\tTop-5 Accuracy 75.373 (74.261)\n",
      "Epoch: [1][15000/17702]\tBatch Time 1.125 (1.078)\tData Load Time 0.406 (0.363)\tLoss 3.3756 (3.3566)\tTop-5 Accuracy 75.346 (74.268)\n",
      "Epoch: [1][15200/17702]\tBatch Time 1.016 (1.078)\tData Load Time 0.344 (0.363)\tLoss 3.1973 (3.3560)\tTop-5 Accuracy 78.693 (74.276)\n",
      "Epoch: [1][15400/17702]\tBatch Time 0.984 (1.078)\tData Load Time 0.266 (0.363)\tLoss 3.5982 (3.3556)\tTop-5 Accuracy 72.752 (74.283)\n",
      "Epoch: [1][15600/17702]\tBatch Time 1.187 (1.079)\tData Load Time 0.375 (0.363)\tLoss 3.4530 (3.3552)\tTop-5 Accuracy 71.018 (74.291)\n",
      "Epoch: [1][15800/17702]\tBatch Time 1.031 (1.078)\tData Load Time 0.328 (0.363)\tLoss 3.5137 (3.3544)\tTop-5 Accuracy 73.585 (74.304)\n",
      "Epoch: [1][16000/17702]\tBatch Time 1.047 (1.078)\tData Load Time 0.359 (0.363)\tLoss 3.2544 (3.3536)\tTop-5 Accuracy 75.457 (74.315)\n",
      "Epoch: [1][16200/17702]\tBatch Time 1.344 (1.078)\tData Load Time 0.422 (0.363)\tLoss 3.4472 (3.3530)\tTop-5 Accuracy 75.000 (74.326)\n",
      "Epoch: [1][16400/17702]\tBatch Time 1.031 (1.078)\tData Load Time 0.359 (0.363)\tLoss 3.6163 (3.3525)\tTop-5 Accuracy 69.565 (74.333)\n",
      "Epoch: [1][16600/17702]\tBatch Time 1.062 (1.078)\tData Load Time 0.437 (0.363)\tLoss 3.0065 (3.3521)\tTop-5 Accuracy 80.290 (74.340)\n",
      "Epoch: [1][16800/17702]\tBatch Time 1.125 (1.078)\tData Load Time 0.406 (0.363)\tLoss 3.1340 (3.3512)\tTop-5 Accuracy 77.188 (74.354)\n",
      "Epoch: [1][17000/17702]\tBatch Time 1.031 (1.078)\tData Load Time 0.312 (0.363)\tLoss 3.1119 (3.3508)\tTop-5 Accuracy 77.344 (74.360)\n",
      "Epoch: [1][17200/17702]\tBatch Time 1.141 (1.078)\tData Load Time 0.453 (0.363)\tLoss 3.1916 (3.3504)\tTop-5 Accuracy 75.910 (74.369)\n",
      "Epoch: [1][17400/17702]\tBatch Time 1.156 (1.078)\tData Load Time 0.406 (0.363)\tLoss 3.2217 (3.3500)\tTop-5 Accuracy 77.143 (74.375)\n",
      "Epoch: [1][17600/17702]\tBatch Time 1.094 (1.078)\tData Load Time 0.375 (0.363)\tLoss 2.9992 (3.3492)\tTop-5 Accuracy 79.944 (74.387)\n",
      "Validation: [0/782]\tBatch Time 0.844 (0.844)\tLoss 3.1729 (3.1729)\tTop-5 Accuracy 74.293 (74.293)\t\n",
      "Validation: [200/782]\tBatch Time 0.406 (0.539)\tLoss 3.4099 (3.2590)\tTop-5 Accuracy 74.855 (75.396)\t\n",
      "Validation: [400/782]\tBatch Time 0.312 (0.452)\tLoss 3.4869 (3.2556)\tTop-5 Accuracy 72.074 (75.492)\t\n",
      "Validation: [600/782]\tBatch Time 0.281 (0.408)\tLoss 3.1957 (3.2593)\tTop-5 Accuracy 78.310 (75.481)\t\n",
      "\n",
      " * LOSS - 3.257, TOP-5 ACCURACY - 75.459, BLEU-4 - 0.22684005588709868\n",
      "\n",
      "Epoch: [2][0/17702]\tBatch Time 2.326 (2.326)\tData Load Time 1.670 (1.670)\tLoss 3.0371 (3.0371)\tTop-5 Accuracy 77.686 (77.686)\n",
      "Epoch: [2][200/17702]\tBatch Time 1.094 (1.124)\tData Load Time 0.328 (0.409)\tLoss 2.9226 (3.2101)\tTop-5 Accuracy 80.274 (76.100)\n",
      "Epoch: [2][400/17702]\tBatch Time 1.016 (1.110)\tData Load Time 0.344 (0.394)\tLoss 2.9974 (3.2163)\tTop-5 Accuracy 79.319 (76.136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][600/17702]\tBatch Time 1.125 (1.109)\tData Load Time 0.437 (0.394)\tLoss 3.1873 (3.2129)\tTop-5 Accuracy 77.446 (76.180)\n",
      "Epoch: [2][800/17702]\tBatch Time 1.078 (1.107)\tData Load Time 0.359 (0.391)\tLoss 2.9688 (3.2193)\tTop-5 Accuracy 80.863 (76.102)\n",
      "Epoch: [2][1000/17702]\tBatch Time 1.297 (1.106)\tData Load Time 0.391 (0.390)\tLoss 3.2531 (3.2198)\tTop-5 Accuracy 77.507 (76.067)\n",
      "Epoch: [2][1200/17702]\tBatch Time 1.094 (1.106)\tData Load Time 0.437 (0.390)\tLoss 2.9060 (3.2192)\tTop-5 Accuracy 79.730 (76.092)\n",
      "Epoch: [2][1400/17702]\tBatch Time 1.094 (1.107)\tData Load Time 0.422 (0.392)\tLoss 3.3950 (3.2224)\tTop-5 Accuracy 74.859 (76.078)\n",
      "Epoch: [2][1600/17702]\tBatch Time 1.234 (1.107)\tData Load Time 0.469 (0.392)\tLoss 3.1844 (3.2231)\tTop-5 Accuracy 77.454 (76.046)\n",
      "Epoch: [2][1800/17702]\tBatch Time 1.047 (1.106)\tData Load Time 0.375 (0.390)\tLoss 3.1322 (3.2228)\tTop-5 Accuracy 74.085 (76.067)\n",
      "Epoch: [2][2000/17702]\tBatch Time 1.078 (1.104)\tData Load Time 0.375 (0.388)\tLoss 3.3495 (3.2228)\tTop-5 Accuracy 72.500 (76.064)\n",
      "Epoch: [2][2200/17702]\tBatch Time 1.031 (1.103)\tData Load Time 0.312 (0.386)\tLoss 3.1641 (3.2228)\tTop-5 Accuracy 78.756 (76.082)\n",
      "Epoch: [2][2400/17702]\tBatch Time 1.094 (1.102)\tData Load Time 0.328 (0.384)\tLoss 3.0323 (3.2237)\tTop-5 Accuracy 78.116 (76.068)\n",
      "Epoch: [2][2600/17702]\tBatch Time 1.078 (1.100)\tData Load Time 0.375 (0.383)\tLoss 3.3157 (3.2232)\tTop-5 Accuracy 75.661 (76.076)\n",
      "Epoch: [2][2800/17702]\tBatch Time 1.031 (1.100)\tData Load Time 0.344 (0.382)\tLoss 3.3114 (3.2242)\tTop-5 Accuracy 76.471 (76.059)\n",
      "Epoch: [2][3000/17702]\tBatch Time 1.172 (1.099)\tData Load Time 0.344 (0.381)\tLoss 3.2545 (3.2238)\tTop-5 Accuracy 76.546 (76.068)\n",
      "Epoch: [2][3200/17702]\tBatch Time 1.109 (1.097)\tData Load Time 0.391 (0.380)\tLoss 3.5600 (3.2232)\tTop-5 Accuracy 68.975 (76.072)\n",
      "Epoch: [2][3400/17702]\tBatch Time 1.141 (1.096)\tData Load Time 0.375 (0.379)\tLoss 3.2464 (3.2217)\tTop-5 Accuracy 76.943 (76.084)\n",
      "Epoch: [2][3600/17702]\tBatch Time 1.078 (1.095)\tData Load Time 0.359 (0.378)\tLoss 2.8358 (3.2220)\tTop-5 Accuracy 80.460 (76.081)\n",
      "Epoch: [2][3800/17702]\tBatch Time 1.000 (1.095)\tData Load Time 0.250 (0.377)\tLoss 3.1393 (3.2218)\tTop-5 Accuracy 77.105 (76.083)\n",
      "Epoch: [2][4000/17702]\tBatch Time 0.953 (1.093)\tData Load Time 0.266 (0.376)\tLoss 3.1466 (3.2224)\tTop-5 Accuracy 77.989 (76.074)\n",
      "Epoch: [2][4200/17702]\tBatch Time 1.078 (1.092)\tData Load Time 0.391 (0.375)\tLoss 3.2096 (3.2223)\tTop-5 Accuracy 76.519 (76.075)\n",
      "Epoch: [2][4400/17702]\tBatch Time 0.984 (1.091)\tData Load Time 0.297 (0.374)\tLoss 3.4438 (3.2230)\tTop-5 Accuracy 74.930 (76.072)\n",
      "Epoch: [2][4600/17702]\tBatch Time 0.969 (1.090)\tData Load Time 0.281 (0.374)\tLoss 3.1969 (3.2237)\tTop-5 Accuracy 74.932 (76.059)\n",
      "Epoch: [2][4800/17702]\tBatch Time 1.047 (1.090)\tData Load Time 0.297 (0.373)\tLoss 2.9033 (3.2229)\tTop-5 Accuracy 82.353 (76.073)\n",
      "Epoch: [2][5000/17702]\tBatch Time 1.016 (1.089)\tData Load Time 0.344 (0.372)\tLoss 3.2590 (3.2224)\tTop-5 Accuracy 75.936 (76.077)\n",
      "Epoch: [2][5200/17702]\tBatch Time 1.016 (1.089)\tData Load Time 0.359 (0.372)\tLoss 3.2975 (3.2226)\tTop-5 Accuracy 76.190 (76.082)\n",
      "Epoch: [2][5400/17702]\tBatch Time 1.047 (1.088)\tData Load Time 0.344 (0.372)\tLoss 3.0575 (3.2226)\tTop-5 Accuracy 77.604 (76.081)\n",
      "Epoch: [2][5600/17702]\tBatch Time 1.094 (1.088)\tData Load Time 0.391 (0.371)\tLoss 3.0581 (3.2222)\tTop-5 Accuracy 78.392 (76.085)\n",
      "Epoch: [2][5800/17702]\tBatch Time 0.922 (1.087)\tData Load Time 0.266 (0.371)\tLoss 3.2194 (3.2214)\tTop-5 Accuracy 77.337 (76.102)\n",
      "Epoch: [2][6000/17702]\tBatch Time 0.984 (1.087)\tData Load Time 0.281 (0.371)\tLoss 3.3565 (3.2219)\tTop-5 Accuracy 74.194 (76.095)\n",
      "Epoch: [2][6200/17702]\tBatch Time 1.094 (1.087)\tData Load Time 0.375 (0.370)\tLoss 3.1118 (3.2220)\tTop-5 Accuracy 79.167 (76.090)\n",
      "Epoch: [2][6400/17702]\tBatch Time 1.078 (1.087)\tData Load Time 0.437 (0.370)\tLoss 3.4604 (3.2225)\tTop-5 Accuracy 73.278 (76.085)\n",
      "Epoch: [2][6600/17702]\tBatch Time 1.047 (1.086)\tData Load Time 0.375 (0.370)\tLoss 3.4224 (3.2223)\tTop-5 Accuracy 72.981 (76.093)\n",
      "Epoch: [2][6800/17702]\tBatch Time 0.984 (1.086)\tData Load Time 0.328 (0.370)\tLoss 2.9959 (3.2222)\tTop-5 Accuracy 80.000 (76.093)\n",
      "Epoch: [2][7000/17702]\tBatch Time 1.016 (1.085)\tData Load Time 0.312 (0.369)\tLoss 3.3593 (3.2221)\tTop-5 Accuracy 73.491 (76.096)\n",
      "Epoch: [2][7200/17702]\tBatch Time 1.000 (1.085)\tData Load Time 0.297 (0.369)\tLoss 3.1183 (3.2223)\tTop-5 Accuracy 76.359 (76.097)\n",
      "Epoch: [2][7400/17702]\tBatch Time 1.141 (1.085)\tData Load Time 0.406 (0.369)\tLoss 3.1854 (3.2223)\tTop-5 Accuracy 76.862 (76.098)\n",
      "Epoch: [2][7600/17702]\tBatch Time 1.031 (1.085)\tData Load Time 0.344 (0.369)\tLoss 3.0995 (3.2220)\tTop-5 Accuracy 78.378 (76.104)\n",
      "Epoch: [2][7800/17702]\tBatch Time 1.156 (1.085)\tData Load Time 0.328 (0.369)\tLoss 3.0282 (3.2218)\tTop-5 Accuracy 79.534 (76.110)\n",
      "Epoch: [2][8000/17702]\tBatch Time 1.109 (1.084)\tData Load Time 0.312 (0.369)\tLoss 3.5658 (3.2216)\tTop-5 Accuracy 72.162 (76.116)\n",
      "Epoch: [2][8200/17702]\tBatch Time 1.078 (1.084)\tData Load Time 0.328 (0.369)\tLoss 2.8369 (3.2217)\tTop-5 Accuracy 79.834 (76.116)\n",
      "Epoch: [2][8400/17702]\tBatch Time 1.078 (1.084)\tData Load Time 0.344 (0.368)\tLoss 3.4515 (3.2216)\tTop-5 Accuracy 71.547 (76.117)\n",
      "Epoch: [2][8600/17702]\tBatch Time 0.969 (1.084)\tData Load Time 0.312 (0.368)\tLoss 3.1241 (3.2215)\tTop-5 Accuracy 75.516 (76.116)\n",
      "Epoch: [2][8800/17702]\tBatch Time 1.062 (1.083)\tData Load Time 0.391 (0.368)\tLoss 2.9110 (3.2213)\tTop-5 Accuracy 79.437 (76.121)\n",
      "Epoch: [2][9000/17702]\tBatch Time 1.078 (1.083)\tData Load Time 0.391 (0.368)\tLoss 3.1327 (3.2214)\tTop-5 Accuracy 78.453 (76.117)\n",
      "Epoch: [2][9200/17702]\tBatch Time 1.000 (1.083)\tData Load Time 0.344 (0.367)\tLoss 2.9685 (3.2214)\tTop-5 Accuracy 79.348 (76.118)\n",
      "Epoch: [2][9400/17702]\tBatch Time 1.125 (1.083)\tData Load Time 0.391 (0.368)\tLoss 3.3424 (3.2211)\tTop-5 Accuracy 74.317 (76.126)\n",
      "Epoch: [2][9600/17702]\tBatch Time 1.031 (1.083)\tData Load Time 0.344 (0.367)\tLoss 3.1978 (3.2209)\tTop-5 Accuracy 76.149 (76.131)\n",
      "Epoch: [2][9800/17702]\tBatch Time 1.172 (1.083)\tData Load Time 0.422 (0.367)\tLoss 3.4686 (3.2207)\tTop-5 Accuracy 73.740 (76.134)\n",
      "Epoch: [2][10000/17702]\tBatch Time 1.109 (1.083)\tData Load Time 0.359 (0.367)\tLoss 2.9059 (3.2208)\tTop-5 Accuracy 79.946 (76.136)\n",
      "Epoch: [2][10200/17702]\tBatch Time 1.047 (1.083)\tData Load Time 0.359 (0.367)\tLoss 2.8641 (3.2212)\tTop-5 Accuracy 81.503 (76.132)\n",
      "Epoch: [2][10400/17702]\tBatch Time 1.125 (1.083)\tData Load Time 0.391 (0.367)\tLoss 2.9150 (3.2213)\tTop-5 Accuracy 80.412 (76.133)\n",
      "Epoch: [2][10600/17702]\tBatch Time 0.953 (1.083)\tData Load Time 0.281 (0.367)\tLoss 3.4099 (3.2213)\tTop-5 Accuracy 73.961 (76.133)\n",
      "Epoch: [2][10800/17702]\tBatch Time 0.984 (1.083)\tData Load Time 0.312 (0.367)\tLoss 3.0002 (3.2216)\tTop-5 Accuracy 77.159 (76.130)\n",
      "Epoch: [2][11000/17702]\tBatch Time 1.141 (1.083)\tData Load Time 0.391 (0.367)\tLoss 3.5002 (3.2215)\tTop-5 Accuracy 74.263 (76.134)\n",
      "Epoch: [2][11200/17702]\tBatch Time 1.141 (1.083)\tData Load Time 0.422 (0.367)\tLoss 3.2144 (3.2214)\tTop-5 Accuracy 76.944 (76.135)\n",
      "Epoch: [2][11400/17702]\tBatch Time 1.203 (1.083)\tData Load Time 0.484 (0.367)\tLoss 3.3738 (3.2213)\tTop-5 Accuracy 73.580 (76.137)\n",
      "Epoch: [2][11600/17702]\tBatch Time 1.156 (1.082)\tData Load Time 0.359 (0.367)\tLoss 3.2874 (3.2213)\tTop-5 Accuracy 74.690 (76.138)\n",
      "Epoch: [2][11800/17702]\tBatch Time 0.984 (1.082)\tData Load Time 0.312 (0.366)\tLoss 3.2186 (3.2207)\tTop-5 Accuracy 77.320 (76.148)\n",
      "Epoch: [2][12000/17702]\tBatch Time 1.078 (1.082)\tData Load Time 0.328 (0.366)\tLoss 3.3815 (3.2207)\tTop-5 Accuracy 72.388 (76.151)\n",
      "Epoch: [2][12200/17702]\tBatch Time 1.078 (1.082)\tData Load Time 0.312 (0.366)\tLoss 3.1343 (3.2203)\tTop-5 Accuracy 78.191 (76.157)\n",
      "Epoch: [2][12400/17702]\tBatch Time 1.078 (1.082)\tData Load Time 0.391 (0.366)\tLoss 3.2749 (3.2202)\tTop-5 Accuracy 75.410 (76.161)\n",
      "Epoch: [2][12600/17702]\tBatch Time 1.031 (1.082)\tData Load Time 0.375 (0.366)\tLoss 3.2378 (3.2206)\tTop-5 Accuracy 76.965 (76.158)\n",
      "Epoch: [2][12800/17702]\tBatch Time 1.078 (1.082)\tData Load Time 0.406 (0.366)\tLoss 2.9971 (3.2205)\tTop-5 Accuracy 78.655 (76.159)\n",
      "Epoch: [2][13000/17702]\tBatch Time 1.094 (1.082)\tData Load Time 0.328 (0.366)\tLoss 2.8493 (3.2205)\tTop-5 Accuracy 82.337 (76.161)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][13200/17702]\tBatch Time 1.250 (1.082)\tData Load Time 0.391 (0.366)\tLoss 3.6423 (3.2207)\tTop-5 Accuracy 71.693 (76.162)\n",
      "Epoch: [2][13400/17702]\tBatch Time 1.047 (1.082)\tData Load Time 0.359 (0.366)\tLoss 3.1192 (3.2205)\tTop-5 Accuracy 77.557 (76.165)\n",
      "Epoch: [2][13600/17702]\tBatch Time 0.953 (1.082)\tData Load Time 0.312 (0.366)\tLoss 3.0581 (3.2202)\tTop-5 Accuracy 77.437 (76.171)\n",
      "Epoch: [2][13800/17702]\tBatch Time 1.125 (1.082)\tData Load Time 0.375 (0.366)\tLoss 3.3854 (3.2202)\tTop-5 Accuracy 73.077 (76.171)\n",
      "Epoch: [2][14000/17702]\tBatch Time 1.187 (1.082)\tData Load Time 0.359 (0.366)\tLoss 3.2290 (3.2202)\tTop-5 Accuracy 75.833 (76.172)\n",
      "Epoch: [2][14200/17702]\tBatch Time 1.016 (1.082)\tData Load Time 0.328 (0.366)\tLoss 3.2873 (3.2203)\tTop-5 Accuracy 76.454 (76.173)\n",
      "Epoch: [2][14400/17702]\tBatch Time 1.031 (1.082)\tData Load Time 0.312 (0.365)\tLoss 3.2381 (3.2205)\tTop-5 Accuracy 74.788 (76.174)\n",
      "Epoch: [2][14600/17702]\tBatch Time 0.953 (1.082)\tData Load Time 0.281 (0.365)\tLoss 3.2307 (3.2203)\tTop-5 Accuracy 73.352 (76.173)\n",
      "Epoch: [2][14800/17702]\tBatch Time 1.047 (1.081)\tData Load Time 0.344 (0.365)\tLoss 3.4134 (3.2200)\tTop-5 Accuracy 72.303 (76.177)\n",
      "Epoch: [2][15000/17702]\tBatch Time 1.078 (1.081)\tData Load Time 0.406 (0.365)\tLoss 2.9621 (3.2198)\tTop-5 Accuracy 80.056 (76.180)\n",
      "Epoch: [2][15200/17702]\tBatch Time 1.047 (1.081)\tData Load Time 0.406 (0.365)\tLoss 3.0206 (3.2198)\tTop-5 Accuracy 78.363 (76.179)\n",
      "Epoch: [2][15400/17702]\tBatch Time 1.016 (1.081)\tData Load Time 0.328 (0.365)\tLoss 3.2574 (3.2198)\tTop-5 Accuracy 75.637 (76.182)\n",
      "Epoch: [2][15600/17702]\tBatch Time 0.937 (1.081)\tData Load Time 0.297 (0.365)\tLoss 2.8420 (3.2197)\tTop-5 Accuracy 82.102 (76.185)\n",
      "Epoch: [2][15800/17702]\tBatch Time 1.109 (1.081)\tData Load Time 0.406 (0.365)\tLoss 3.1768 (3.2194)\tTop-5 Accuracy 78.173 (76.187)\n",
      "Epoch: [2][16000/17702]\tBatch Time 1.075 (1.081)\tData Load Time 0.340 (0.365)\tLoss 3.3105 (3.2196)\tTop-5 Accuracy 74.242 (76.186)\n",
      "Epoch: [2][16200/17702]\tBatch Time 1.141 (1.081)\tData Load Time 0.422 (0.365)\tLoss 3.3587 (3.2194)\tTop-5 Accuracy 74.211 (76.189)\n",
      "Epoch: [2][16400/17702]\tBatch Time 1.031 (1.081)\tData Load Time 0.375 (0.365)\tLoss 3.0911 (3.2194)\tTop-5 Accuracy 80.000 (76.191)\n",
      "Epoch: [2][16600/17702]\tBatch Time 0.969 (1.081)\tData Load Time 0.328 (0.365)\tLoss 3.1876 (3.2192)\tTop-5 Accuracy 78.035 (76.196)\n",
      "Epoch: [2][16800/17702]\tBatch Time 1.062 (1.081)\tData Load Time 0.344 (0.365)\tLoss 3.0920 (3.2191)\tTop-5 Accuracy 76.923 (76.197)\n",
      "Epoch: [2][17000/17702]\tBatch Time 1.062 (1.081)\tData Load Time 0.344 (0.365)\tLoss 2.9862 (3.2192)\tTop-5 Accuracy 77.348 (76.201)\n",
      "Epoch: [2][17200/17702]\tBatch Time 1.016 (1.081)\tData Load Time 0.328 (0.365)\tLoss 3.5878 (3.2191)\tTop-5 Accuracy 69.855 (76.205)\n",
      "Epoch: [2][17400/17702]\tBatch Time 1.047 (1.080)\tData Load Time 0.344 (0.364)\tLoss 3.4691 (3.2190)\tTop-5 Accuracy 73.037 (76.206)\n",
      "Epoch: [2][17600/17702]\tBatch Time 1.078 (1.081)\tData Load Time 0.391 (0.364)\tLoss 3.2581 (3.2189)\tTop-5 Accuracy 77.540 (76.208)\n",
      "Validation: [0/782]\tBatch Time 0.781 (0.781)\tLoss 3.1796 (3.1796)\tTop-5 Accuracy 75.000 (75.000)\t\n",
      "Validation: [200/782]\tBatch Time 0.391 (0.530)\tLoss 3.0339 (3.1950)\tTop-5 Accuracy 78.182 (76.325)\t\n",
      "Validation: [400/782]\tBatch Time 0.328 (0.448)\tLoss 3.3192 (3.2094)\tTop-5 Accuracy 74.176 (76.175)\t\n",
      "Validation: [600/782]\tBatch Time 0.297 (0.404)\tLoss 3.2227 (3.2043)\tTop-5 Accuracy 75.603 (76.219)\t\n",
      "\n",
      " * LOSS - 3.198, TOP-5 ACCURACY - 76.309, BLEU-4 - 0.23172476754783003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Epochs\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "        if fine_tune_encoder:\n",
    "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "          encoder=encoder,\n",
    "          decoder=decoder,\n",
    "          criterion=criterion,\n",
    "          encoder_optimizer=encoder_optimizer,\n",
    "          decoder_optimizer=decoder_optimizer,\n",
    "          epoch=epoch)\n",
    "\n",
    "    # One epoch's validation\n",
    "    recent_bleu4 = validate(val_loader=val_loader,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            criterion=criterion)\n",
    "\n",
    "    # Check if there was an improvement\n",
    "    is_best = recent_bleu4 > best_bleu4\n",
    "    best_bleu4 = max(recent_bleu4, best_bleu4)\n",
    "    if not is_best:\n",
    "        epochs_since_improvement += 1\n",
    "        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "    else:\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                    decoder_optimizer, recent_bleu4, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
